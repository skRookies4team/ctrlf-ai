# ctrlf-ai-gateway 환경변수 설정 예시
# 이 파일을 복사하여 .env 파일을 생성하세요: cp .env.example .env

# =============================================================================
# 앱 기본 설정
# =============================================================================
APP_NAME=ctrlf-ai-gateway
APP_ENV=local  # local / dev / prod
APP_VERSION=0.1.0
LOG_LEVEL=INFO  # DEBUG / INFO / WARNING / ERROR

# =============================================================================
# AI 환경 모드 (mock / real)
# =============================================================================
# mock: Docker Compose 내 Mock 서비스 사용 (통합 테스트용)
# real: 실제 서비스 연결 (프로덕션/스테이징용)
AI_ENV=real

# =============================================================================
# Mock 모드 서비스 URL (로컬 실행용)
# =============================================================================
LLM_BASE_URL_MOCK=http://localhost:8001
RAGFLOW_BASE_URL_MOCK=http://localhost:8080

# =============================================================================
# 직접 지정 URL (AI_ENV보다 우선)
# =============================================================================
LLM_BASE_URL=http://localhost:8001
LLM_MODEL_NAME=LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct
EMBEDDING_MODEL_NAME=BAAI/bge-m3

# =============================================================================
# Real 모드 URL 설정
# =============================================================================
RAGFLOW_BASE_URL_REAL=
LLM_BASE_URL_REAL=
BACKEND_BASE_URL_REAL=

# =============================================================================
# RAGFlow 설정
# =============================================================================
RAGFLOW_API_KEY=
RAGFLOW_EMBEDDING_MODEL=text-embedding-3-large@OpenAI

# =============================================================================
# LLM 모델 설정
# =============================================================================
# 채팅/FAQ용 LLM 모델
LLM_MODEL_NAME=LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct

# 스크립트 생성용 LLM 모델 (미설정 시 LLM_MODEL_NAME 사용)
SCRIPT_LLM_MODEL=

# =============================================================================
# OpenAI 임베딩 / LLM 설정
# =============================================================================
OPENAI_API_KEY=
OPENAI_EMBED_MODEL=text-embedding-3-large
OPENAI_EMBED_DIM=3072

# =============================================================================
# Milvus Dataset Mapping (domain:dataset_id)
# =============================================================================
# 실제 Milvus ragflow_chunks 컬렉션의 dataset_id 값
# POLICY: 사내규정
# EDUCATION: 정보보안교육, 직무교육, 장애인인식개선교육, 직장내괴롭힘교육, 직장내성희롱교육
MILVUS_DATASET_MAPPING=POLICY:사내규정,EDUCATION:정보보안교육,EDUCATION:직무교육,EDUCATION:장애인인식개선교육,EDUCATION:직장내괴롭힘교육,EDUCATION:직장내성희롱교육

# =============================================================================
# Backend 연동 설정
# =============================================================================
BACKEND_BASE_URL=http://localhost:8080
BACKEND_BASE_URL=

# =============================================================================
# PII 마스킹 설정
# =============================================================================
PII_ENABLED=false

# =============================================================================
# CORS 설정
# =============================================================================
# 개발: * (모든 origin 허용)
# 프로덕션: https://your-domain.com (특정 도메인만)
CORS_ORIGINS=*

# =============================================================================
# Phase 24: Milvus Vector Database 설정
# =============================================================================
MILVUS_ENABLED=true
RETRIEVAL_BACKEND=milvus  # ragflow / milvus
EMBEDDING_CONTRACT_STRICT=true
MILVUS_HOST=localhost
MILVUS_PORT=19530
MILVUS_COLLECTION_NAME=ragflow_chunks

# =============================================================================
# vLLM Embeddings 설정
# =============================================================================
EMBEDDING_MODEL_NAME=BAAI/bge-m3
EMBEDDING_DIMENSION=768

# =============================================================================
# Milvus 검색 설정
# =============================================================================
MILVUS_TOP_K=5
MILVUS_SEARCH_PARAMS={"metric_type":"L2","params":{"nprobe":10}}

# =============================================================================
# Phase 25: 인덱싱 파이프라인 설정
# =============================================================================
CHUNK_SIZE=512
CHUNK_OVERLAP=50
INDEX_RETRY_MAX_ATTEMPTS=3
INDEX_RETRY_BACKOFF_SECONDS=1,2,4
FILE_DOWNLOAD_TIMEOUT_SEC=60.0
FILE_MAX_SIZE_MB=50
SUPPORTED_FILE_EXTENSIONS=.pdf,.txt,.docx,.doc,.hwp

# =============================================================================
# 내부 API 인증 토큰
# =============================================================================
# Backend → AI 요청 시 사용 (예: /internal/ai/rag-documents/ingest)
BACKEND_INTERNAL_TOKEN=

# RAGFlow → AI 콜백 요청 시 사용 (예: /internal/ai/callbacks/ragflow/ingest)
RAGFLOW_CALLBACK_TOKEN=

# AI → Backend 스토리지 API 요청 시 사용 (Presigned URL 발급 등)
BACKEND_SERVICE_TOKEN=

# AI → Backend 일반 API 요청 시 사용 (Authorization: Bearer)
BACKEND_API_TOKEN=
