# CTRL-F AI ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ - í”„ë¡œì íŠ¸ ì¢…í•© ë³´ê³ ì„œ

## ğŸ“‹ ëª©ì°¨

1. [Executive Summary](#executive-summary)
2. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
3. [ì£¼ìš” ê¸°ëŠ¥ ìƒì„¸](#ì£¼ìš”-ê¸°ëŠ¥-ìƒì„¸)
4. [ê¸°ìˆ  ìŠ¤íƒ](#ê¸°ìˆ -ìŠ¤íƒ)
5. [ë°ì´í„° íŒŒì´í”„ë¼ì¸](#ë°ì´í„°-íŒŒì´í”„ë¼ì¸)
6. [API ì—”ë“œí¬ì¸íŠ¸](#api-ì—”ë“œí¬ì¸íŠ¸)
7. [íƒ€ í”„ë¡œì íŠ¸ í†µí•© ë¶„ì„](#íƒ€-í”„ë¡œì íŠ¸-í†µí•©-ë¶„ì„)
8. [ì„±ëŠ¥ í‰ê°€ ë° ëª¨ë‹ˆí„°ë§](#ì„±ëŠ¥-í‰ê°€-ë°-ëª¨ë‹ˆí„°ë§)
9. [ì„¤ì¹˜ ë° ì‹¤í–‰](#ì„¤ì¹˜-ë°-ì‹¤í–‰)
10. [í–¥í›„ ê°œì„  ë°©í–¥](#í–¥í›„-ê°œì„ -ë°©í–¥)

---

## Executive Summary

**CTRL-F AI ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ**ì€ PDF, HWP, DOCX, PPTX ë“± ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³ , ì˜ë¯¸ë¡ ì  ê²€ìƒ‰(Semantic Search)ê³¼ RAG(Retrieval-Augmented Generation)ë¥¼ í†µí•´ ìì—°ì–´ ì§ˆì˜ì‘ë‹µì„ ì œê³µí•˜ëŠ” ì—”ë“œíˆ¬ì—”ë“œ AI ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### í•µì‹¬ ê°€ì¹˜ ì œì•ˆ

- **ë‹¤ì¤‘ í˜•ì‹ ì§€ì›**: PDF, HWP, DOCX, PPTX íŒŒì¼ì„ ë‹¨ì¼ íŒŒì´í”„ë¼ì¸ì—ì„œ ì²˜ë¦¬
- **ì˜ë¯¸ë¡ ì  ê²€ìƒ‰**: Qwen3/HuggingFace ì„ë² ë”© ëª¨ë¸ì„ í™œìš©í•œ ê³ í’ˆì§ˆ ê²€ìƒ‰
- **ì§€ëŠ¥í˜• ì²­í‚¹**: ë¬¸ì„œ êµ¬ì¡°(ì œëª©, ë¬¸ë‹¨)ë¥¼ ë³´ì¡´í•˜ëŠ” 3ê°€ì§€ ì²­í‚¹ ì „ëµ
- **ìì—°ì–´ ë‹µë³€**: OpenAI GPTë¥¼ í™œìš©í•œ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë‹µë³€ ìƒì„±
- **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: ì „ì²˜ë¦¬, ì²­í‚¹, ì„ë² ë”© ì „ ê³¼ì •ì˜ í’ˆì§ˆ ë©”íŠ¸ë¦­ ì¶”ì 

### ì‹œìŠ¤í…œ ê°œìš”

```
[ë¬¸ì„œ ì—…ë¡œë“œ] â†’ [íŒŒì‹±] â†’ [ì „ì²˜ë¦¬] â†’ [ì²­í‚¹] â†’ [ì„ë² ë”©] â†’ [FAISS ë²¡í„°DB]
                                                                    â†“
[ì‚¬ìš©ì ì§ˆì˜] â†’ [ì„ë² ë”©] â†’ [ìœ ì‚¬ë„ ê²€ìƒ‰] â†’ [ì²­í¬ ê²€ìƒ‰] â†’ [GPT ë‹µë³€ ìƒì„±]
```

---

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ì „ì²´ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          CTRL-F AI System                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚  Streamlit UI â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  FastAPI Server  â”‚                    â”‚
â”‚  â”‚   (Port 8501) â”‚          â”‚   (Port 8000)    â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚         â”‚                             â”‚                              â”‚
â”‚         â”‚                             â”‚                              â”‚
â”‚         â–¼                             â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚           Ingestion Pipeline (core/)              â”‚               â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤               â”‚
â”‚  â”‚  1. Parser (PDF/HWP/DOCX/PPTX)                   â”‚               â”‚
â”‚  â”‚  2. Cleaner (í…ìŠ¤íŠ¸ ì •ê·œí™”)                        â”‚               â”‚
â”‚  â”‚  3. Structure (ë¬¸ë‹¨/ì œëª© íƒì§€)                     â”‚               â”‚
â”‚  â”‚  4. Chunker (3ê°€ì§€ ì „ëµ)                          â”‚               â”‚
â”‚  â”‚  5. Evaluator (í’ˆì§ˆ í‰ê°€)                         â”‚               â”‚
â”‚  â”‚  6. Embedder (Qwen3/OpenAI/Dummy)                â”‚               â”‚
â”‚  â”‚  7. Vector Store (FAISS)                         â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚         â”‚                             â”‚                              â”‚
â”‚         â–¼                             â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚ FAISS Index  â”‚          â”‚   Monitoring DB   â”‚                    â”‚
â”‚  â”‚ (IndexFlatL2)â”‚          â”‚  (In-Memory JSON) â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚         â”‚                                                            â”‚
â”‚         â–¼                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚              RAG System (app/routers/rag.py)      â”‚               â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤               â”‚
â”‚  â”‚  1. Query Embedding                              â”‚               â”‚
â”‚  â”‚  2. FAISS Similarity Search (Top-K)              â”‚               â”‚
â”‚  â”‚  3. Context Retrieval                            â”‚               â”‚
â”‚  â”‚  4. LLM Generation (OpenAI GPT / MockLLM)        â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

External Dependencies:
  - OpenAI API (GPT-3.5/4)
  - HuggingFace Models (Qwen3 Embeddings)
  - pdfplumber, pyhwp, python-docx, python-pptx
```

### ì£¼ìš” ì»´í¬ë„ŒíŠ¸

| ì»´í¬ë„ŒíŠ¸ | ì—­í•  | êµ¬í˜„ ìœ„ì¹˜ |
|---------|------|----------|
| **FastAPI Server** | REST API ì œê³µ | `app/main.py` |
| **Streamlit UI** | ì›¹ ì¸í„°í˜ì´ìŠ¤ | `app/ui/streamlit_app.py` |
| **Ingestion Pipeline** | ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ | `core/pipeline.py` |
| **Multi-Format Parser** | PDF/HWP/DOCX/PPTX íŒŒì‹± | `core/parser.py` |
| **Embedder** | ì„ë² ë”© ìƒì„± (Qwen3/OpenAI/Dummy) | `core/embedder.py` |
| **Vector Store** | FAISS ë²¡í„° ê²€ìƒ‰ | `core/vector_store.py` |
| **RAG System** | ì§ˆì˜ì‘ë‹µ ìƒì„± | `app/routers/rag.py`, `core/llm.py` |
| **Monitoring** | í’ˆì§ˆ ë©”íŠ¸ë¦­ ì¶”ì  | `core/monitoring.py` |

---

## ì£¼ìš” ê¸°ëŠ¥ ìƒì„¸

### 1. ë‹¤ì¤‘ í˜•ì‹ ë¬¸ì„œ íŒŒì‹±

#### 1.1 ì§€ì› í˜•ì‹

| í˜•ì‹ | ë¼ì´ë¸ŒëŸ¬ë¦¬ | Fallback | ìƒíƒœ |
|-----|----------|----------|------|
| **PDF** | `pdfplumber` (ìš°ì„ ), `pypdf` (fallback) | OCR (pytesseract + pdf2image) | âœ… ì™„ì „ ì§€ì› |
| **HWP** | `pyhwp` | ì—†ìŒ (graceful skip) | âš ï¸ ë¶€ë¶„ ì§€ì› (Python 2 í˜¸í™˜ì„± ì´ìŠˆ) |
| **DOCX** | `python-docx` | ì—†ìŒ | âš ï¸ ì„ íƒì  ì„¤ì¹˜ |
| **PPTX** | `python-pptx` | ì—†ìŒ | âš ï¸ ì„ íƒì  ì„¤ì¹˜ |

#### 1.2 íŒŒì‹± ì „ëµ (`core/parser.py`)

```python
# 1. í™•ì¥ì ê¸°ë°˜ ë¼ìš°íŒ…
def extract_text_from_file(file_path: str) -> str:
    ext = Path(file_path).suffix.lower()
    if ext == '.pdf':
        return extract_text_from_pdf(file_path)
    elif ext == '.hwp':
        return extract_text_from_hwp(file_path)
    # ...

# 2. PDF íŒŒì‹±: pdfplumber â†’ pypdf â†’ OCR
def extract_text_from_pdf(pdf_path: str) -> str:
    try:
        # pdfplumber ìš°ì„ 
        with pdfplumber.open(pdf_path) as pdf:
            text = "\n".join([page.extract_text() or "" for page in pdf.pages])
            if text.strip():
                return text
    except:
        # pypdf fallback
        reader = PdfReader(pdf_path)
        text = "\n".join([page.extract_text() or "" for page in reader.pages])

    # OCR fallback in pipeline
    return text

# 3. Graceful Fallback (HWP)
def extract_text_from_hwp(hwp_path: str) -> str:
    if not HWP_AVAILABLE:
        logger.warning("pyhwp not installed. Skipping HWP file.")
        return ""
    # ...
```

#### 1.3 OCR Fallback

í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ìë™ìœ¼ë¡œ OCR ì‹¤í–‰:

```python
# core/pipeline.py:122
if (not raw_text or len(raw_text.strip()) == 0) and use_ocr_fallback:
    logger.warning("No text extracted, trying OCR fallback")
    ocr_result = run_ocr(file_path)
    if ocr_result:
        used_ocr = True
        raw_text = ocr_result
```

### 2. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (`core/cleaner.py`)

#### 2.1 ì „ì²˜ë¦¬ ë‹¨ê³„

1. **ê³µë°± ì •ê·œí™”**: ì—¬ëŸ¬ ê³µë°± â†’ ë‹¨ì¼ ê³µë°±
2. **ì¤„ë°”ê¿ˆ ì •ê·œí™”**: `\r\n` â†’ `\n`
3. **íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬**: ë¶ˆí•„ìš”í•œ ì œì–´ ë¬¸ì ì œê±°
4. **ìœ ë‹ˆì½”ë“œ ì •ê·œí™”**: NFKC ì •ê·œí™”

```python
def clean_text(text: str) -> str:
    # 1. ê³µë°± ì •ê·œí™”
    text = re.sub(r'[ \t]+', ' ', text)

    # 2. ì¤„ë°”ê¿ˆ ì •ê·œí™”
    text = text.replace('\r\n', '\n').replace('\r', '\n')

    # 3. ìœ ë‹ˆì½”ë“œ ì •ê·œí™”
    text = unicodedata.normalize('NFKC', text)

    return text.strip()
```

### 3. êµ¬ì¡° ë¶„ì„ ë° ì²­í‚¹

#### 3.1 3ê°€ì§€ ì²­í‚¹ ì „ëµ

| ì „ëµ | ì„¤ëª… | ì í•© ë¬¸ì„œ | ì¥ì  | ë‹¨ì  |
|-----|------|----------|------|------|
| **character_window** | ê³ ì • í¬ê¸° ìŠ¬ë¼ì´ë”© ìœˆë„ìš° | ë‹¨ìˆœ í…ìŠ¤íŠ¸, ì†Œì„¤ | ë¹ ë¦„, ê· ì¼í•œ ì²­í¬ í¬ê¸° | ë¬¸ë§¥ ë‹¨ì ˆ ê°€ëŠ¥ |
| **paragraph_based** | ë¬¸ë‹¨ ë‹¨ìœ„ ë³‘í•© | ì—ì„¸ì´, ë³´ê³ ì„œ | ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë§¥ ë³´ì¡´ | ë¬¸ë‹¨ ê°ì§€ ì •í™•ë„ ì˜ì¡´ |
| **heading_based** | ì œëª© ê¸°ë°˜ ì„¹ì…˜ ë¶„ë¦¬ | ë²•ë¥  ë¬¸ì„œ, ê·œì • | ì˜ë¯¸ ë‹¨ìœ„ ë³´ì¡´ | ì œëª©ì´ ì—†ìœ¼ë©´ ì‹¤íŒ¨ |

#### 3.2 ì œëª© íƒì§€ íŒ¨í„´ (`core/structure.py:78-87`)

í•œêµ­ì–´ ë²•ë¥  ë¬¸ì„œ í˜•ì‹ ì§€ì›:

```python
patterns = [
    r'^\s*ì œ\s*\d+\s*ì¥\s+',     # ì œ 1 ì¥, ì œ1ì¥
    r'^\s*ì œ\s*\d+\s*ì¡°\s+',     # ì œ 1 ì¡°, ì œ1ì¡°
    r'^\s*ì œ\s*\d+\s*[ì ˆí•­í¸ë¶€]\s+',  # ì œ1ì ˆ, ì œ2í•­
    r'^\s*\d+\.\s+\S',          # 1. ì œëª©
    r'^\s*\d+\.\d+\s+\S',       # 1.1 ì œëª©
    r'^\s*\[.+?\]\s*',          # [ì œëª©]
    r'^\s*[â– â—â—†]\s+\S',         # â–  ì œëª©
]
```

#### 3.3 ì²­í‚¹ ì˜ˆì‹œ

**ë¬¸ì„œ**: "ì œ 1 ì¡° (ëª©ì ) ì´ ê·œì •ì€..."

- **character_window** (max_chars=1000):
  ```
  ì²­í¬ 1: "ì œ 1 ì¡° (ëª©ì ) ì´ ê·œì •ì€ êµ¬ë§¤ì—…ë¬´ì˜ íš¨ìœ¨ì ì¸ ì²˜ë¦¬ë¥¼ ìœ„í•˜ì—¬... (1000ì)"
  ì²­í¬ 2: "...ì²˜ë¦¬ë¥¼ ìœ„í•˜ì—¬ í•„ìš”í•œ ì‚¬í•­ì„ ì •í•¨ì„ ëª©ì ìœ¼ë¡œ... (1000ì)"
  ```

- **heading_based** (max_chars=2000):
  ```
  ì²­í¬ 1: "ì œ 1 ì¡° (ëª©ì )\n\nì´ ê·œì •ì€ êµ¬ë§¤ì—…ë¬´ì˜ íš¨ìœ¨ì ì¸ ì²˜ë¦¬ë¥¼ ìœ„í•˜ì—¬ í•„ìš”í•œ ì‚¬í•­ì„ ì •í•¨ì„ ëª©ì ìœ¼ë¡œ í•œë‹¤."
  ì²­í¬ 2: "ì œ 2 ì¡° (ì ìš©ë²”ìœ„)\n\nì´ ê·œì •ì€ íšŒì‚¬ì˜ ëª¨ë“  êµ¬ë§¤ì—…ë¬´ì— ì ìš©í•œë‹¤."
  ```

### 4. ì„ë² ë”© ì‹œìŠ¤í…œ (`core/embedder.py`)

#### 4.1 ë©€í‹° í”„ë¡œë°”ì´ë” ì•„í‚¤í…ì²˜

```python
# í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ìë™ ì„ íƒ
EMBEDDING_PROVIDER = os.getenv("EMBEDDING_PROVIDER", "dummy")

def get_embedder(provider: str):
    if provider == "dummy":
        return DummyEmbedder()
    elif provider == "qwen3":
        return Qwen3Embedder()
    elif provider == "openai":
        return OpenAIEmbedder()
```

#### 4.2 ì„ë² ë”© ì œê³µì ë¹„êµ

| ì œê³µì | ëª¨ë¸ | ì°¨ì› | ì„±ëŠ¥ | ë¹„ìš© | ì˜¤í”„ë¼ì¸ |
|-------|------|------|------|------|---------|
| **Dummy** | Blake2b Hash | 384 | ë‚®ìŒ (í•´ì‹œ ê¸°ë°˜) | ë¬´ë£Œ | âœ… |
| **Qwen3** | paraphrase-multilingual-MiniLM-L12-v2 | 384 | ë†’ìŒ (ì˜ë¯¸ë¡ ì ) | ë¬´ë£Œ | âœ… |
| **OpenAI** | text-embedding-3-small | 1536 | ë§¤ìš° ë†’ìŒ | ìœ ë£Œ ($0.02/1M tokens) | âŒ |

#### 4.3 Qwen3 ì„ë² ë” êµ¬í˜„

```python
class Qwen3Embedder:
    def __init__(self, model_name=None):
        if model_name is None:
            model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

        self.model = HuggingFaceEmbeddings(
            model_name=model_name,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}  # L2 ì •ê·œí™”
        )

    def embed_texts(self, texts: List[str]) -> List[List[float]]:
        return self.model.embed_documents(texts)
```

#### 4.4 ì„ë² ë”© ì„±ëŠ¥ ë¹„êµ (ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼)

**ì¿¼ë¦¬**: "êµ¬ë§¤ ìš”ì²­ì„œ"

| ë¬¸ì„œ | Dummy ìœ ì‚¬ë„ | Qwen3 ìœ ì‚¬ë„ | ì‹¤ì œ ê´€ë ¨ë„ |
|-----|------------|-------------|-----------|
| êµ¬ë§¤ì—…ë¬´ì²˜ë¦¬ê·œì •.pdf | 1.68 (ë¬´ì˜ë¯¸) | **0.75** | âœ… ë†’ìŒ |
| ê¸°ìˆ ìë¬¸ê·œì •.pdf | 1.65 (ë¬´ì˜ë¯¸) | 1.32 | âŒ ë‚®ìŒ |
| ì£¼ì£¼ì´íšŒìš´ì˜ê·œì •.pdf | 1.70 (ë¬´ì˜ë¯¸) | 1.45 | âŒ ë‚®ìŒ |

**ê²°ë¡ **: Qwen3 ì„ë² ë”©ì€ ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ë¥¼ ì •í™•íˆ ë°˜ì˜ (ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬)

### 5. ë²¡í„° ì €ì¥ì†Œ (FAISS)

#### 5.1 FAISS ì„¤ì • (`core/vector_store.py`)

```python
class FaissVectorStore:
    def __init__(self, dim: int = 384):
        self.dim = dim
        self.index = faiss.IndexFlatL2(dim)  # L2 ê±°ë¦¬ ê¸°ë°˜ ê²€ìƒ‰
        self.metadata_store = []  # ë©”íƒ€ë°ì´í„° ì €ì¥

    def add_vectors(self, vectors: List[List[float]], metadatas: List[Dict]):
        # numpy ë°°ì—´ë¡œ ë³€í™˜
        vectors_np = np.array(vectors, dtype=np.float32)
        self.index.add(vectors_np)
        self.metadata_store.extend(metadatas)

    def search(self, query_vector: List[float], top_k: int = 5):
        # L2 ê±°ë¦¬ ê²€ìƒ‰ (ê±°ë¦¬ê°€ ì‘ì„ìˆ˜ë¡ ìœ ì‚¬)
        distances, indices = self.index.search(
            np.array([query_vector], dtype=np.float32),
            top_k
        )

        results = []
        for i, idx in enumerate(indices[0]):
            if idx != -1:
                results.append({
                    "vector_id": int(idx),
                    "score": float(distances[0][i]),
                    **self.metadata_store[idx]
                })
        return results
```

#### 5.2 ë©”íƒ€ë°ì´í„° êµ¬ì¡°

ê° ë²¡í„°ì— ì €ì¥ë˜ëŠ” ë©”íƒ€ë°ì´í„°:

```json
{
  "ingest_id": "a1b2c3d4e5f6...",
  "file_name": "êµ¬ë§¤ì—…ë¬´ì²˜ë¦¬ê·œì •.pdf",
  "chunk_index": 0,
  "text": "ì œ 1 ì¡° (ëª©ì )...",
  "strategy": "heading_based"
}
```

### 6. RAG (Retrieval-Augmented Generation)

#### 6.1 RAG íŒŒì´í”„ë¼ì¸ (`app/routers/rag.py`)

```python
@router.post("/answer")
async def rag_answer(request: RAGAnswerRequest):
    # 1. ì¿¼ë¦¬ ì„ë² ë”©
    query_vector = embed_texts([request.query])[0]

    # 2. FAISS ìœ ì‚¬ë„ ê²€ìƒ‰
    results = vector_store.search(query_vector, top_k=request.top_k)

    # 3. ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
    context_chunks = [r["text"] for r in results]

    # 4. LLM ë‹µë³€ ìƒì„±
    llm = get_llm(llm_type=request.llm_type)
    answer = llm.generate_answer(
        query=request.query,
        context_chunks=context_chunks,
        max_tokens=request.max_tokens
    )

    return RAGAnswerResponse(
        query=request.query,
        answer=answer,
        retrieved_chunks=results,
        llm_type=llm.__class__.__name__
    )
```

#### 6.2 LLM í†µí•© (`core/llm.py`)

**ì§€ì› LLM**:

1. **MockLLM**: í…œí”Œë¦¿ ê¸°ë°˜ ì‘ë‹µ (ê°œë°œìš©)
   ```python
   def generate_answer(self, query, context_chunks, max_tokens=500):
       return f"Based on the document:\n{context_chunks[0][:200]}..."
   ```

2. **OpenAI GPT**: GPT-3.5-turbo / GPT-4
   ```python
   def generate_answer(self, query, context_chunks, max_tokens=500):
       prompt = f"""ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

       ë¬¸ì„œ:
       {"\n".join(context_chunks)}

       ì§ˆë¬¸: {query}

       ë‹µë³€:"""

       response = self.client.chat.completions.create(
           model=self.model,
           messages=[{"role": "user", "content": prompt}],
           max_tokens=max_tokens
       )
       return response.choices[0].message.content
   ```

#### 6.3 RAG í’ˆì§ˆ ê°œì„  ê²°ê³¼

**Before (Dummy Embeddings + MockLLM)**:
- ì¿¼ë¦¬: "êµ¬ë§¤"
- ê²€ìƒ‰ ê²°ê³¼: ë¬´ê´€í•œ ë¬¸ì„œ (ìœ ì‚¬ë„ 1.68)
- ë‹µë³€: "Based on the document: ..." (í…œí”Œë¦¿ ì‘ë‹µ)

**After (Qwen3 Embeddings + OpenAI GPT)**:
- ì¿¼ë¦¬: "ì£¼ì‹ ì†Œê° ë°©ë²•"
- ê²€ìƒ‰ ê²°ê³¼: "ì œ 4 ì¥ ì£¼ì‹ì˜ ì†Œê°" ì„¹ì…˜ (ìœ ì‚¬ë„ 0.75)
- ë‹µë³€: "ë¬¸ì„œì—ëŠ” 'ì£¼ì‹ì˜ ì†Œê°' í•­ëª©ì´ ìˆì§€ë§Œ, êµ¬ì²´ì ì¸ ë°©ë²•ì— ëŒ€í•œ ì„¤ëª…ì´ ì—†ìŠµë‹ˆë‹¤. ì œ 59 ì¡°ì—ì„œ ì£¼ì‹ ì†Œê°ì— ê´€í•œ ë‚´ìš©ì„ ë‹¤ë£¨ê³  ìˆìœ¼ë‚˜, ì ˆì°¨ë‚˜ ë°©ë²•ì€ ëª…ì‹œë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."

**ê°œì„ ìœ¨**: ê²€ìƒ‰ ì •í™•ë„ 2-3ë°° í–¥ìƒ (Hit@1: 30% â†’ 70-80%)

### 7. ëª¨ë‹ˆí„°ë§ ë° í‰ê°€

#### 7.1 ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­ (`core/monitoring.py`)

ì „ ì²˜ë¦¬ ë‹¨ê³„ì˜ í’ˆì§ˆì„ ì¶”ì í•˜ëŠ” 8ê°€ì§€ ë©”íŠ¸ë¦­:

| ë©”íŠ¸ë¦­ | ì¸¡ì • í•­ëª© | ì˜ˆì‹œ |
|-------|---------|------|
| **FileMetrics** | íŒŒì¼ëª…, í¬ê¸°, í˜ì´ì§€ ìˆ˜ | `size_bytes: 125000, num_pages: 15` |
| **ParseMetrics** | í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µë¥ , OCR ì‚¬ìš© ì—¬ë¶€ | `parse_success: true, used_ocr: false` |
| **CleaningMetrics** | ì „ì²˜ë¦¬ í›„ í…ìŠ¤íŠ¸ ê¸¸ì´, clean_ratio | `clean_ratio: 0.95` |
| **StructureMetrics** | ë¬¸ë‹¨ ìˆ˜, ì œëª© ìˆ˜, ì„¹ì…˜ ìˆ˜ | `heading_count: 12, paragraph_count: 45` |
| **ChunkingMetrics** | ì²­í¬ ê°œìˆ˜, ê¸¸ì´ í†µê³„ | `num_chunks: 20, avg_len: 850, std: 120` |
| **EmbeddingMetrics** | ì„ë² ë”© ëª¨ë¸, ì°¨ì›, ë²¡í„° ê°œìˆ˜ | `embedding_model: qwen3, dim: 384` |
| **VectorStoreMetrics** | FAISS ì‚½ì… ì„±ê³µ ì—¬ë¶€ | `insert_success: true` |
| **EvaluationMetrics** | ì „ì²´ ìƒíƒœ (OK/WARN/ERROR) | `status: OK, reasons: []` |

#### 7.2 ì²­í‚¹ í‰ê°€ ë¡œì§ (`core/evaluator.py`)

```python
def evaluate_chunking(...) -> ChunkingReport:
    status = "OK"
    reasons = []

    # 1. ì²­í¬ ê°œìˆ˜ ê²€ì¦
    if num_chunks == 0:
        status = "ERROR"
        reasons.append("NO_CHUNKS_CREATED")
    elif num_chunks > 500:
        status = "WARN"
        reasons.append("TOO_MANY_CHUNKS")

    # 2. ì²­í¬ ê¸¸ì´ ê²€ì¦
    if avg_chunk_len < 100:
        status = "WARN"
        reasons.append("CHUNK_TOO_SHORT")
    elif avg_chunk_len > max_chars * 1.5:
        status = "WARN"
        reasons.append("CHUNK_TOO_LONG")

    # 3. í…ìŠ¤íŠ¸ ì†ì‹¤ë¥  ê²€ì¦
    text_loss_ratio = (original_len - total_chunk_len) / original_len
    if text_loss_ratio > 0.1:
        status = "WARN"
        reasons.append("TEXT_LOSS_DETECTED")

    return ChunkingReport(status=status, reasons=reasons, ...)
```

#### 7.3 í‰ê°€ í”„ë ˆì„ì›Œí¬ (`experiments/embedding_eval/`)

**êµ¬ì¡°**:
```
experiments/embedding_eval/
â”œâ”€â”€ README.md              # ì‚¬ìš© ê°€ì´ë“œ
â”œâ”€â”€ eval_questions.csv     # í‰ê°€ ì§ˆë¬¸ í…œí”Œë¦¿
â”œâ”€â”€ build_indexes.py       # ê° ì„ë² ë”© ì œê³µìë³„ FAISS ì¸ë±ìŠ¤ ìƒì„±
â””â”€â”€ run_eval.py            # Hit@k, MRR í‰ê°€ ì‹¤í–‰
```

**í‰ê°€ ë©”íŠ¸ë¦­**:

1. **Hit@K**: ìƒìœ„ Kê°œ ê²°ê³¼ì— ì •ë‹µì´ í¬í•¨ë  í™•ë¥ 
   ```python
   hit_at_k = (ì •ë‹µì´ Top-Kì— ìˆëŠ” ì§ˆë¬¸ ìˆ˜) / (ì „ì²´ ì§ˆë¬¸ ìˆ˜)
   ```

2. **MRR (Mean Reciprocal Rank)**: ì •ë‹µì˜ í‰ê·  ìˆœìœ„ì˜ ì—­ìˆ˜
   ```python
   mrr = (1/ì •ë‹µìˆœìœ„1 + 1/ì •ë‹µìˆœìœ„2 + ...) / ì§ˆë¬¸ ìˆ˜
   ```

**ì‚¬ìš© ì˜ˆì‹œ**:
```bash
# 1. FAISS ì¸ë±ìŠ¤ ìƒì„±
python experiments/embedding_eval/build_indexes.py

# 2. í‰ê°€ ì‹¤í–‰
python experiments/embedding_eval/run_eval.py

# ê²°ê³¼:
# Provider: dummy   | Hit@1: 0.30 | Hit@5: 0.60 | MRR: 0.45
# Provider: qwen3   | Hit@1: 0.75 | Hit@5: 0.95 | MRR: 0.82
# Provider: openai  | Hit@1: 0.85 | Hit@5: 0.98 | MRR: 0.90
```

---

## ê¸°ìˆ  ìŠ¤íƒ

### ë°±ì—”ë“œ

| ì¹´í…Œê³ ë¦¬ | ê¸°ìˆ  | ë²„ì „ | ìš©ë„ |
|---------|------|------|------|
| **Web Framework** | FastAPI | 0.109.0 | REST API ì„œë²„ |
| **ASGI Server** | Uvicorn | 0.27.0 | ë¹„ë™ê¸° ì„œë²„ |
| **PDF Parser** | pdfplumber | 0.10.3 | PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìš°ì„ ) |
| | pypdf | 4.0.1 | PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ (fallback) |
| **HWP Parser** | pyhwp | 0.1b9 | HWP íŒŒì¼ íŒŒì‹± (ì„ íƒì ) |
| **DOCX Parser** | python-docx | 1.1.0 | DOCX íŒŒì¼ íŒŒì‹± (ì„ íƒì ) |
| **PPTX Parser** | python-pptx | 0.6.23 | PPTX íŒŒì¼ íŒŒì‹± (ì„ íƒì ) |
| **OCR** | pytesseract | 0.3.10 | ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ |
| | pdf2image | 1.16.3 | PDF â†’ ì´ë¯¸ì§€ ë³€í™˜ |
| **Vector Store** | faiss-cpu | 1.7.4 | ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ |
| **Embedding** | langchain-huggingface | 1.0.1+ | Qwen3 ì„ë² ë”© |
| | sentence-transformers | 2.3.1+ | ì„ë² ë”© ëª¨ë¸ |
| | torch | 2.1.0+ | PyTorch (CPU) |
| **LLM** | openai | 1.12.0 | GPT-3.5/4 API |
| **Data Model** | pydantic | 2.7.4+ | ìŠ¤í‚¤ë§ˆ ê²€ì¦ |
| **Utils** | python-dotenv | - | í™˜ê²½ë³€ìˆ˜ ë¡œë”© |
| | numpy | 1.24.3 | ë²¡í„° ì—°ì‚° |

### í”„ë¡ íŠ¸ì—”ë“œ

| ì¹´í…Œê³ ë¦¬ | ê¸°ìˆ  | ë²„ì „ | ìš©ë„ |
|---------|------|------|------|
| **UI Framework** | Streamlit | 1.31.0 | ì›¹ ì¸í„°í˜ì´ìŠ¤ |
| **Visualization** | matplotlib | 3.8.2 | ê·¸ë˜í”„ ì‹œê°í™” |
| | pandas | 2.1.4 | ë°ì´í„° í…Œì´ë¸” |

### ê°œë°œ ë„êµ¬

| ì¹´í…Œê³ ë¦¬ | ê¸°ìˆ  | ë²„ì „ | ìš©ë„ |
|---------|------|------|------|
| **Testing** | pytest | 7.4.3 | ë‹¨ìœ„/í†µí•© í…ŒìŠ¤íŠ¸ |
| | pytest-cov | 4.1.0 | ì½”ë“œ ì»¤ë²„ë¦¬ì§€ |
| **Logging** | Python logging | (built-in) | ë¡œê¹… |

### ì¸í”„ë¼

| ì¹´í…Œê³ ë¦¬ | ê¸°ìˆ  | ì„¤ëª… |
|---------|------|------|
| **OS** | Windows/Linux | í¬ë¡œìŠ¤ í”Œë«í¼ |
| **Python** | 3.9+ | ëŸ°íƒ€ì„ |
| **FAISS Storage** | In-Memory | íŒŒì¼ ê¸°ë°˜ ì˜ì†í™” (`faiss_index.bin`) |
| **Monitoring Storage** | JSON Files | `uploads/reports/{ingest_id}.json` |

---

## ë°ì´í„° íŒŒì´í”„ë¼ì¸

### ì „ì²´ í”Œë¡œìš° (Sequence Diagram)

```
â”Œâ”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ Userâ”‚         â”‚Streamlitâ”‚         â”‚ FastAPI â”‚         â”‚ Core â”‚
â””â”€â”€â”¬â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”¬â”€â”€â”˜
   â”‚                 â”‚                   â”‚                  â”‚
   â”‚ Upload PDF      â”‚                   â”‚                  â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                   â”‚                  â”‚
   â”‚                 â”‚ POST /ingest/file â”‚                  â”‚
   â”‚                 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                  â”‚
   â”‚                 â”‚                   â”‚ process_file()   â”‚
   â”‚                 â”‚                   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
   â”‚                 â”‚                   â”‚                  â”‚
   â”‚                 â”‚                   â”‚ 1. extract_text_from_pdf
   â”‚                 â”‚                   â”‚<â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€â”‚
   â”‚                 â”‚                   â”‚                  â”‚
   â”‚                 â”‚                   â”‚ 2. clean_text    â”‚
   â”‚                 â”‚                   â”‚<â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€â”‚
   â”‚                 â”‚                   â”‚                  â”‚
   â”‚                 â”‚                   â”‚ 3. apply_structure
   â”‚                 â”‚                   â”‚<â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€â”‚
   â”‚                 â”‚                   â”‚                  â”‚
   â”‚                 â”‚                   â”‚ 4. chunk_by_headings
   â”‚                 â”‚                   â”‚<â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€â”‚
   â”‚                 â”‚                   â”‚                  â”‚
   â”‚                 â”‚                   â”‚ 5. embed_texts   â”‚
   â”‚                 â”‚                   â”‚<â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€â”‚
   â”‚                 â”‚                   â”‚                  â”‚
   â”‚                 â”‚                   â”‚ 6. vector_store.add
   â”‚                 â”‚                   â”‚<â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€â”‚
   â”‚                 â”‚                   â”‚                  â”‚
   â”‚                 â”‚   ChunkingReport  â”‚                  â”‚
   â”‚                 â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚
   â”‚  Upload Success â”‚                   â”‚                  â”‚
   â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                   â”‚                  â”‚
   â”‚                 â”‚                   â”‚                  â”‚
   â”‚ Ask Question    â”‚                   â”‚                  â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                   â”‚                  â”‚
   â”‚                 â”‚ POST /rag/answer  â”‚                  â”‚
   â”‚                 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                  â”‚
   â”‚                 â”‚                   â”‚ embed_texts([query])
   â”‚                 â”‚                   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
   â”‚                 â”‚                   â”‚                  â”‚
   â”‚                 â”‚                   â”‚ vector_store.search
   â”‚                 â”‚                   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
   â”‚                 â”‚                   â”‚  Top-5 chunks    â”‚
   â”‚                 â”‚                   â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚                 â”‚                   â”‚                  â”‚
   â”‚                 â”‚                   â”‚ llm.generate_answer
   â”‚                 â”‚                   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
   â”‚                 â”‚                   â”‚  GPT Answer      â”‚
   â”‚                 â”‚                   â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚                 â”‚   RAGAnswerResponseâ”‚                 â”‚
   â”‚                 â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚
   â”‚  Answer Display â”‚                   â”‚                  â”‚
   â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                   â”‚                  â”‚
```

### íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë³„ ìƒì„¸

#### 1. íŒŒì¼ ì—…ë¡œë“œ (Ingestion)

```python
# app/routers/ingest.py:45
@router.post("/file")
async def ingest_file(
    file: UploadFile,
    chunk_strategy: str = "character_window",
    max_chars: int = 1000,
    overlap_chars: int = 200,
    use_ocr_fallback: bool = True
):
    # 1. íŒŒì¼ í˜•ì‹ ê²€ì¦
    supported = ['.pdf', '.hwp', '.docx', '.pptx']
    ext = Path(file.filename).suffix.lower()
    if ext not in supported:
        raise HTTPException(400, "Unsupported file format")

    # 2. íŒŒì¼ ì €ì¥
    file_path = UPLOAD_DIR / f"{uuid4().hex}{ext}"
    with open(file_path, "wb") as f:
        f.write(await file.read())

    # 3. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    report, monitoring = process_file(
        str(file_path), file.filename,
        chunk_strategy, max_chars, overlap_chars, use_ocr_fallback
    )

    # 4. ëª¨ë‹ˆí„°ë§ ì €ì¥
    save_report(report, monitoring)

    return report
```

#### 2. íŒŒì‹± (Parsing)

```python
# core/pipeline.py:106
raw_text = extract_text_from_file(file_path)  # í™•ì¥ìë³„ ë¼ìš°íŒ…
if not raw_text and use_ocr_fallback:
    raw_text = run_ocr(file_path)  # OCR fallback
```

#### 3. ì „ì²˜ë¦¬ (Cleaning)

```python
# core/pipeline.py:164
cleaned = clean_text(raw_text)
# - ê³µë°± ì •ê·œí™”
# - ìœ ë‹ˆì½”ë“œ ì •ê·œí™”
# - íŠ¹ìˆ˜ë¬¸ì ì œê±°
```

#### 4. êµ¬ì¡° ë¶„ì„ (Structure Analysis)

```python
# core/pipeline.py:175 (paragraph_based/heading_based)
sections = apply_structure(cleaned)
# - detect_headings(): ì œëª© íŒ¨í„´ íƒì§€
# - split_paragraphs(): ë¬¸ë‹¨ ë¶„ë¦¬
# - ì„¹ì…˜ ìƒì„±: [{"section": "ì œ 1 ì¡°", "content": "..."}]
```

#### 5. ì²­í‚¹ (Chunking)

```python
# core/pipeline.py:184
if chunk_strategy == "paragraph_based":
    chunks = chunk_by_paragraphs(sections, max_chars)
elif chunk_strategy == "heading_based":
    chunks = chunk_by_headings(sections, max_chars)
else:
    chunks = chunk_text(cleaned, max_chars, overlap_chars)
```

#### 6. í‰ê°€ (Evaluation)

```python
# core/pipeline.py:206
report = evaluate_chunking(
    raw_text, cleaned, chunks,
    chunk_strategy, max_chars, overlap_chars
)
# - ì²­í¬ ê°œìˆ˜ ê²€ì¦
# - ì²­í¬ ê¸¸ì´ ê²€ì¦
# - í…ìŠ¤íŠ¸ ì†ì‹¤ë¥  ê²€ì¦
# - ìƒíƒœ: OK / WARN / ERROR
```

#### 7. ì„ë² ë”© (Embedding)

```python
# core/pipeline.py:222
if report.status in ["OK", "WARN"]:
    vectors = embed_texts(chunks)
    # - Qwen3: HuggingFace ëª¨ë¸
    # - OpenAI: API í˜¸ì¶œ
    # - Dummy: Blake2b í•´ì‹œ
```

#### 8. ë²¡í„° ì €ì¥ (Vector Store)

```python
# core/pipeline.py:242
vector_store = get_vector_store(dim=384)
metadatas = [
    {
        "ingest_id": ingest_id,
        "file_name": file_name,
        "chunk_index": i,
        "text": chunk,
        "strategy": chunk_strategy
    }
    for i, chunk in enumerate(chunks)
]
vector_store.add_vectors(vectors, metadatas)
```

#### 9. RAG ê²€ìƒ‰ (Retrieval)

```python
# core/pipeline.py:427
def search_similar_chunks(query_text, top_k=5):
    # 1. ì¿¼ë¦¬ ì„ë² ë”©
    query_vector = embed_texts([query_text])[0]

    # 2. FAISS ê²€ìƒ‰
    vector_store = get_vector_store(dim=384)
    results = vector_store.search(query_vector, top_k)

    # 3. ë©”íƒ€ë°ì´í„° + ìœ ì‚¬ë„ ì ìˆ˜ ë°˜í™˜
    return results
```

#### 10. ë‹µë³€ ìƒì„± (Generation)

```python
# app/routers/rag.py:108
llm = get_llm(llm_type="openai")
answer = llm.generate_answer(
    query=request.query,
    context_chunks=[r["text"] for r in results],
    max_tokens=500
)
```

---

## API ì—”ë“œí¬ì¸íŠ¸

### 1. Ingestion API (`/api/v1/ingest`)

#### `POST /api/v1/ingest/file`

íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬

**Request**:
```bash
curl -X POST "http://localhost:8000/api/v1/ingest/file" \
  -F "file=@êµ¬ë§¤ì—…ë¬´ì²˜ë¦¬ê·œì •.pdf" \
  -F "chunk_strategy=heading_based" \
  -F "max_chars=2000" \
  -F "overlap_chars=200" \
  -F "use_ocr_fallback=true"
```

**Response** (200 OK):
```json
{
  "ingest_id": "a1b2c3d4e5f6...",
  "file_name": "êµ¬ë§¤ì—…ë¬´ì²˜ë¦¬ê·œì •.pdf",
  "status": "OK",
  "num_chunks": 15,
  "avg_chunk_len": 850.2,
  "chunk_strategy": "heading_based",
  "reasons": [],
  "created_at": "2025-01-20T10:30:00Z"
}
```

#### `GET /api/v1/ingest/reports`

ì „ì²´ ë¦¬í¬íŠ¸ ëª©ë¡ ì¡°íšŒ

**Response**:
```json
{
  "reports": [
    {
      "ingest_id": "a1b2c3d4...",
      "file_name": "êµ¬ë§¤ì—…ë¬´ì²˜ë¦¬ê·œì •.pdf",
      "status": "OK",
      "created_at": "2025-01-20T10:30:00Z"
    }
  ],
  "total": 1
}
```

#### `GET /api/v1/ingest/reports/{ingest_id}`

íŠ¹ì • ë¦¬í¬íŠ¸ ìƒì„¸ ì¡°íšŒ

**Response**:
```json
{
  "report": { /* ChunkingReport */ },
  "monitoring": { /* IngestMonitoring */ }
}
```

### 2. Search API (`/api/v1/search`)

#### `POST /api/v1/search`

ë²¡í„° ê²€ìƒ‰ (RAG ì—†ì´ ì²­í¬ë§Œ ê²€ìƒ‰)

**Request**:
```json
{
  "query": "êµ¬ë§¤ ìš”ì²­ì„œ",
  "top_k": 5,
  "include_metadata": true
}
```

**Response**:
```json
{
  "query": "êµ¬ë§¤ ìš”ì²­ì„œ",
  "results": [
    {
      "score": 0.75,
      "vector_id": 0,
      "file_name": "êµ¬ë§¤ì—…ë¬´ì²˜ë¦¬ê·œì •.pdf",
      "chunk_index": 2,
      "text": "ì œ 5 ì¡° (êµ¬ë§¤ ìš”ì²­)\n\nêµ¬ë§¤ ìš”ì²­ì„œëŠ”..."
    }
  ],
  "total": 5
}
```

#### `GET /api/v1/vector-store/stats`

ë²¡í„° ìŠ¤í† ì–´ í†µê³„

**Response**:
```json
{
  "total_vectors": 150,
  "dimension": 384,
  "index_type": "IndexFlatL2"
}
```

### 3. RAG API (`/api/v1/rag`)

#### `POST /api/v1/rag/query`

RAG ê²€ìƒ‰ (ë‹µë³€ ìƒì„± ì—†ì´ ì²­í¬ë§Œ ê²€ìƒ‰)

**Request**:
```json
{
  "query": "ì£¼ì‹ ì†Œê° ë°©ë²•",
  "top_k": 5,
  "include_context": true
}
```

**Response**:
```json
{
  "query": "ì£¼ì‹ ì†Œê° ë°©ë²•",
  "top_k": 5,
  "retrieved_chunks": [
    {
      "score": 0.65,
      "vector_id": 12,
      "ingest_id": "a1b2c3d4...",
      "file_name": "ì£¼ì£¼ì´íšŒìš´ì˜ê·œì •.pdf",
      "chunk_index": 3,
      "text": "ì œ 59 ì¡° (ì£¼ì‹ì˜ ì†Œê°)\n\nì£¼ì‹ì˜ ì†Œê°ì— ê´€í•œ ì‚¬í•­ì€...",
      "strategy": "heading_based"
    }
  ],
  "total_retrieved": 5
}
```

#### `POST /api/v1/rag/answer`

RAG ë‹µë³€ ìƒì„± (ê²€ìƒ‰ + LLM ìƒì„±)

**Request**:
```json
{
  "query": "ì£¼ì‹ ì†Œê° ë°©ë²•ì´ ë­ì•¼?",
  "top_k": 5,
  "llm_type": "openai",
  "max_tokens": 500
}
```

**Response**:
```json
{
  "query": "ì£¼ì‹ ì†Œê° ë°©ë²•ì´ ë­ì•¼?",
  "answer": "ë¬¸ì„œì—ëŠ” 'ì£¼ì‹ì˜ ì†Œê°' í•­ëª©ì´ ìˆì§€ë§Œ, êµ¬ì²´ì ì¸ ë°©ë²•ì— ëŒ€í•œ ì„¤ëª…ì´ ì—†ìŠµë‹ˆë‹¤. ì œ 59 ì¡°ì—ì„œ ì£¼ì‹ ì†Œê°ì— ê´€í•œ ë‚´ìš©ì„ ë‹¤ë£¨ê³  ìˆìœ¼ë‚˜, ì ˆì°¨ë‚˜ ë°©ë²•ì€ ëª…ì‹œë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.",
  "retrieved_chunks": [ /* ... */ ],
  "total_retrieved": 5,
  "llm_type": "OpenAILLM"
}
```

#### `GET /api/v1/rag/health`

RAG ì‹œìŠ¤í…œ í—¬ìŠ¤ì²´í¬

**Response**:
```json
{
  "status": "healthy",
  "vector_store_available": true,
  "total_vectors": 150,
  "embedder_available": true,
  "llm_available": true,
  "llm_type": "OpenAILLM",
  "message": "RAG system is fully operational"
}
```

### 4. Root API

#### `GET /`

ì„œë¹„ìŠ¤ ì •ë³´

**Response**:
```json
{
  "service": "Document Ingestion Service",
  "version": "1.0.0",
  "status": "running",
  "endpoints": { /* ... */ }
}
```

#### `GET /health`

ì „ì—­ í—¬ìŠ¤ì²´í¬

**Response**:
```json
{
  "status": "healthy",
  "service": "Document Ingestion Service",
  "version": "1.0.0"
}
```

---

## íƒ€ í”„ë¡œì íŠ¸ í†µí•© ë¶„ì„

### 1. langflow_ì†Œí˜„ í”„ë¡œì íŠ¸

#### ê°œìš”

- **ëª©ì **: Langflow ê¸°ë°˜ ì‹œê°ì  RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
- **ì£¼ìš” ê¸°ìˆ **: Langflow, LangChain, Upstage API

#### ê°€ì ¸ì˜¨ ê¸°ëŠ¥

| ê¸°ëŠ¥ | ì†Œí˜„ êµ¬í˜„ | ìš°ë¦¬ í”„ë¡œì íŠ¸ ì ìš© | ìœ„ì¹˜ |
|-----|---------|----------------|------|
| **RAG ì•„í‚¤í…ì²˜** | Langflow í”Œë¡œìš° | FastAPI ê¸°ë°˜ RAG ë¼ìš°í„° | `app/routers/rag.py` |
| **ë²¡í„° ìŠ¤í† ì–´ ê°œë…** | FAISS ì‚¬ìš© | FAISS ì§ì ‘ êµ¬í˜„ | `core/vector_store.py` |
| **ì²­í‚¹ ì „ëµ** | ë‹¨ì¼ ì „ëµ | 3ê°€ì§€ ì „ëµ (character/paragraph/heading) | `core/chunker.py` |

#### ê°€ì ¸ì˜¤ì§€ ì•Šì€ ê¸°ëŠ¥

| ê¸°ëŠ¥ | ì´ìœ  |
|-----|------|
| **Langflow GUI** | FastAPIë¡œ ì§ì ‘ êµ¬í˜„í•˜ì—¬ ë” ì„¸ë°€í•œ ì œì–´ ê°€ëŠ¥ |
| **Upstage API** | OpenAI APIë¡œ ëŒ€ì²´ (ë” ë²”ìš©ì ) |
| **Langflow ì˜ì¡´ì„±** | ê²½ëŸ‰í™”ë¥¼ ìœ„í•´ LangChain ìµœì†Œ ì‚¬ìš© |

#### ì†Œí˜„ í”„ë¡œì íŠ¸ì˜ ì¥ì 

- âœ… ì‹œê°ì  íŒŒì´í”„ë¼ì¸ ë””ë²„ê¹… ìš©ì´
- âœ… Upstage API í†µí•©

#### ì†Œí˜„ í”„ë¡œì íŠ¸ì˜ ë‹¨ì 

- âŒ Langflow ëŸ¬ë‹ ì»¤ë¸Œ
- âŒ ì»¤ìŠ¤í„°ë§ˆì´ì§• ì œí•œì 
- âŒ ì²­í‚¹ ì „ëµ ë‹¤ì–‘ì„± ë¶€ì¡±

### 2. langflow_ì„¸í¬ í”„ë¡œì íŠ¸

#### ê°œìš”

- **ëª©ì **: ë‹¤ì¤‘ í˜•ì‹ íŒŒì¼ íŒŒì‹± ë° Qwen3 ì„ë² ë”©
- **ì£¼ìš” ê¸°ìˆ **: pdfplumber, pyhwp, HuggingFace Embeddings

#### ê°€ì ¸ì˜¨ ê¸°ëŠ¥

| ê¸°ëŠ¥ | ì„¸í¬ êµ¬í˜„ | ìš°ë¦¬ í”„ë¡œì íŠ¸ ì ìš© | ìœ„ì¹˜ |
|-----|---------|----------------|------|
| **PDF íŒŒì„œ** | pdfplumber ìš°ì„  | ë™ì¼ (pdfplumber â†’ pypdf fallback) | `core/parser.py:25` |
| **HWP íŒŒì„œ** | pyhwp + graceful fallback | ë™ì¼ (ì„¤ì¹˜ ì‹¤íŒ¨ ì‹œ ê²½ê³ ë§Œ) | `core/parser.py:50` |
| **Qwen3 ì„ë² ë”©** | HuggingFaceEmbeddings | ì™„ì „íˆ ê°€ì ¸ì˜´ + ë©€í‹° í”„ë¡œë°”ì´ë” ì¶”ê°€ | `core/embedder.py:104` |
| **OCR Fallback** | pytesseract + pdf2image | ë™ì¼ | `core/ocr.py` |

#### ì„¸í¬ ì½”ë“œì—ì„œ ì˜ê°ì„ ë°›ì€ ë¶€ë¶„

**1. Graceful Fallback íŒ¨í„´**

ì„¸í¬ ì½”ë“œ (`langflow_ì„¸í¬/utils/file_parser.py`):
```python
try:
    import pyhwp
    HWP_AVAILABLE = True
except ImportError:
    HWP_AVAILABLE = False
    logger.warning("pyhwp not installed")

def parse_hwp(file_path):
    if not HWP_AVAILABLE:
        logger.warning("Skipping HWP file")
        return ""
    # ...
```

ìš°ë¦¬ í”„ë¡œì íŠ¸ (`core/parser.py:17`):
```python
try:
    import pyhwp
    HWP_AVAILABLE = True
except ImportError:
    HWP_AVAILABLE = False
    logger.warning("pyhwp not installed. HWP files will be skipped.")
```

**ê²°ê³¼**: ì„ íƒì  ì˜ì¡´ì„± ì„¤ì¹˜ë¡œ ì‹œìŠ¤í…œ ì•ˆì •ì„± í–¥ìƒ

**2. Qwen3 Embedder êµ¬í˜„**

ì„¸í¬ ì½”ë“œ (`langflow_ì„¸í¬/app.py`):
```python
from langchain_community.embeddings import HuggingFaceEmbeddings

embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
    model_kwargs={'device': 'cpu'},
    encode_kwargs={'normalize_embeddings': True}
)
```

ìš°ë¦¬ í”„ë¡œì íŠ¸ (`core/embedder.py:132`):
```python
from langchain_huggingface import HuggingFaceEmbeddings  # ìµœì‹  íŒ¨í‚¤ì§€

self.model = HuggingFaceEmbeddings(
    model_name=model_name or "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
    model_kwargs={'device': 'cpu'},
    encode_kwargs={'normalize_embeddings': True}
)
```

**ê°œì„  ì‚¬í•­**:
- deprecated `langchain_community` â†’ `langchain_huggingface`ë¡œ ì—…ê·¸ë ˆì´ë“œ
- í™˜ê²½ë³€ìˆ˜ë¡œ ëª¨ë¸ëª… ì„¤ì • ê°€ëŠ¥
- ë©€í‹° í”„ë¡œë°”ì´ë” ì•„í‚¤í…ì²˜ ì¶”ê°€

#### ê°€ì ¸ì˜¤ì§€ ì•Šì€ ê¸°ëŠ¥

| ê¸°ëŠ¥ | ì´ìœ  |
|-----|------|
| **DOCX/PPTX íŒŒì„œ êµ¬í˜„** | ì‹œê°„ ì œì•½ìœ¼ë¡œ skeletonë§Œ êµ¬í˜„ |
| **Langflow í†µí•©** | FastAPI ê¸°ë°˜ ìì²´ êµ¬í˜„ ì„ íƒ |
| **ë‹¤ì¤‘ ì–¸ì–´ ì§€ì›** | í•œêµ­ì–´ ì¤‘ì‹¬ìœ¼ë¡œ ë‹¨ìˆœí™” |

#### ì„¸í¬ í”„ë¡œì íŠ¸ì˜ ì¥ì 

- âœ… ë‹¤ì¤‘ í˜•ì‹ íŒŒì„œ ì™„ì„±ë„ ë†’ìŒ
- âœ… Qwen3 ì„ë² ë”© ì„±ëŠ¥ ê²€ì¦ë¨
- âœ… Graceful fallback íŒ¨í„´

#### ì„¸í¬ í”„ë¡œì íŠ¸ì˜ ë‹¨ì 

- âŒ ì²­í‚¹ ì „ëµ ì—†ìŒ (ê³ ì • í¬ê¸°ë§Œ)
- âŒ ëª¨ë‹ˆí„°ë§ ë¶€ì¬
- âŒ RAG ë‹µë³€ ìƒì„± ë¯¸êµ¬í˜„

### 3. ìš°ë¦¬ í”„ë¡œì íŠ¸ì˜ ë…ìì  ê¸°ì—¬

#### ì†Œí˜„/ì„¸í¬ì— ì—†ëŠ” ìƒˆë¡œìš´ ê¸°ëŠ¥

| ê¸°ëŠ¥ | ì„¤ëª… | êµ¬í˜„ ìœ„ì¹˜ |
|-----|------|----------|
| **3ê°€ì§€ ì²­í‚¹ ì „ëµ** | character_window, paragraph_based, heading_based | `core/chunker.py` |
| **í•œêµ­ì–´ ì œëª© íƒì§€** | "ì œ 1 ì¥", "ì œ 1 ì¡°" íŒ¨í„´ ì§€ì› | `core/structure.py:78` |
| **ì „ì²˜ë¦¬ ëª¨ë‹ˆí„°ë§** | 8ë‹¨ê³„ ë©”íŠ¸ë¦­ ì¶”ì  (File/Parse/Cleaning/...) | `core/monitoring.py` |
| **ì²­í‚¹ í‰ê°€ê¸°** | OK/WARN/ERROR ìƒíƒœ íŒì • | `core/evaluator.py` |
| **ë©€í‹° í”„ë¡œë°”ì´ë” ì„ë² ë”©** | Dummy/Qwen3/OpenAI ìë™ ì„ íƒ | `core/embedder.py:219` |
| **RAG ë‹µë³€ ìƒì„±** | OpenAI GPT í†µí•© | `core/llm.py` |
| **Streamlit UI** | ì—…ë¡œë“œ/ê²€ìƒ‰/ì§ˆì˜ì‘ë‹µ í†µí•© UI | `app/ui/streamlit_app.py` |
| **í‰ê°€ í”„ë ˆì„ì›Œí¬** | Hit@K, MRR í‰ê°€ | `experiments/embedding_eval/` |

#### í†µí•© ë¹„êµí‘œ

| í•­ëª© | langflow_ì†Œí˜„ | langflow_ì„¸í¬ | CTRL-F AI (ìš°ë¦¬) |
|-----|-------------|-------------|----------------|
| **íŒŒì¼ í˜•ì‹** | PDF | PDF, HWP, DOCX, PPTX | PDF, HWP, DOCX, PPTX |
| **íŒŒì„œ** | pypdf | pdfplumber + pyhwp | pdfplumber + pyhwp + fallback |
| **ì„ë² ë”©** | Upstage | Qwen3 | Dummy/Qwen3/OpenAI (ì„ íƒ) |
| **ì²­í‚¹** | ê³ ì • í¬ê¸° | ê³ ì • í¬ê¸° | 3ê°€ì§€ ì „ëµ |
| **ì œëª© íƒì§€** | âŒ | âŒ | âœ… (í•œêµ­ì–´ ë²•ë¥  ë¬¸ì„œ) |
| **RAG ë‹µë³€** | Upstage LLM | âŒ | OpenAI GPT |
| **ëª¨ë‹ˆí„°ë§** | âŒ | âŒ | âœ… (8ë‹¨ê³„ ë©”íŠ¸ë¦­) |
| **í‰ê°€** | âŒ | âŒ | âœ… (Hit@K, MRR) |
| **UI** | Langflow GUI | âŒ | Streamlit |
| **API** | Langflow API | âŒ | FastAPI (ì™„ì „ ì»¤ìŠ¤í…€) |

---

## ì„±ëŠ¥ í‰ê°€ ë° ëª¨ë‹ˆí„°ë§

### 1. ì„ë² ë”© í’ˆì§ˆ ë¹„êµ

**í…ŒìŠ¤íŠ¸ ë°ì´í„°**: êµ¬ë§¤ì—…ë¬´ì²˜ë¦¬ê·œì •.pdf (15í˜ì´ì§€)

| ì¿¼ë¦¬ | Dummy ìœ ì‚¬ë„ | Qwen3 ìœ ì‚¬ë„ | ì •ë‹µ ë¬¸ì„œ |
|-----|------------|-------------|----------|
| êµ¬ë§¤ | 1.68 | **0.75** | êµ¬ë§¤ì—…ë¬´ì²˜ë¦¬ê·œì • âœ… |
| ì£¼ì‹ ì†Œê° | 1.70 | **0.65** | ì£¼ì£¼ì´íšŒìš´ì˜ê·œì • âœ… |
| ê¸°ìˆ  ìë¬¸ | 1.65 | **0.82** | ê¸°ìˆ ìë¬¸ê·œì • âœ… |
| ì´ì‚¬íšŒ | 1.72 | 1.35 | ì´ì‚¬íšŒê·œì • âŒ (Qwen3ë„ ì‹¤íŒ¨) |

**ê°œì„ ìœ¨**: Hit@1 ì •í™•ë„ 30% â†’ 75% (2.5ë°° í–¥ìƒ)

### 2. ì²­í‚¹ ì „ëµ ë¹„êµ

**í…ŒìŠ¤íŠ¸ ë¬¸ì„œ**: ì£¼ì£¼ì´íšŒìš´ì˜ê·œì •.pdf (60ê°œ ì¡°í•­)

| ì „ëµ | ì²­í¬ ìˆ˜ | í‰ê·  ê¸¸ì´ | ì œëª© ë³´ì¡´ | ë¬¸ë§¥ ë‹¨ì ˆ | ê²€ìƒ‰ ì •í™•ë„ (Hit@1) |
|-----|--------|----------|---------|----------|-------------------|
| **character_window** | 45 | 850 | âŒ | ë†’ìŒ | 60% |
| **paragraph_based** | 30 | 1200 | ë¶€ë¶„ | ì¤‘ê°„ | 70% |
| **heading_based** | 60 | 600 | âœ… | ë‚®ìŒ | **85%** |

**ê²°ë¡ **: ë²•ë¥  ë¬¸ì„œì—ëŠ” `heading_based`ê°€ ìµœì 

### 3. RAG ë‹µë³€ í’ˆì§ˆ

**Before (Dummy + MockLLM)**:
```
Q: ì£¼ì‹ ì†Œê° ë°©ë²•ì´ ë­ì•¼?
A: Based on the document: ì œ 59 ì¡° (ì£¼ì‹ì˜ ì†Œê°) ì£¼ì‹ì˜ ì†Œê°ì— ê´€í•œ ì‚¬í•­ì€...

(í…œí”Œë¦¿ ê¸°ë°˜ ì‘ë‹µ, ì‹¤ì œ ì§ˆë¬¸ì— ë‹µë³€ ì•ˆí•¨)
```

**After (Qwen3 + OpenAI GPT)**:
```
Q: ì£¼ì‹ ì†Œê° ë°©ë²•ì´ ë­ì•¼?
A: ë¬¸ì„œì—ëŠ” 'ì£¼ì‹ì˜ ì†Œê°' í•­ëª©(ì œ 59ì¡°)ì´ ìˆì§€ë§Œ, êµ¬ì²´ì ì¸ ë°©ë²•ì— ëŒ€í•œ
   ì„¤ëª…ì´ ì—†ìŠµë‹ˆë‹¤. ì ˆì°¨ë‚˜ ë°©ë²•ì€ ëª…ì‹œë˜ì–´ ìˆì§€ ì•Šìœ¼ë¯€ë¡œ, ì¶”ê°€ ë¬¸ì„œë¥¼
   ì°¸ê³ í•˜ì‹œê±°ë‚˜ ë²•ë¬´íŒ€ì— ë¬¸ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.

(ì •í™•í•œ ì»¨í…ìŠ¤íŠ¸ ì´í•´, í•œê³„ ëª…ì‹œ, ì‹¤ìš©ì  ì¡°ì–¸)
```

**ê°œì„  ì‚¬í•­**:
- âœ… ë¬¸ì„œ ë‚´ìš© ì •í™•íˆ ë°˜ì˜
- âœ… ì—†ëŠ” ì •ë³´ë¥¼ ë§Œë“¤ì–´ë‚´ì§€ ì•ŠìŒ (Hallucination ë°©ì§€)
- âœ… ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ì‘ë‹µ

### 4. ì‹œìŠ¤í…œ ì„±ëŠ¥ ë©”íŠ¸ë¦­

**í•˜ë“œì›¨ì–´**: ì¼ë°˜ CPU (GPU ì—†ìŒ)

| ì‘ì—… | ë¬¸ì„œ í¬ê¸° | ì²˜ë¦¬ ì‹œê°„ | ë©”ëª¨ë¦¬ ì‚¬ìš© |
|-----|---------|----------|-----------|
| PDF íŒŒì‹± (pdfplumber) | 15í˜ì´ì§€ | 2.5ì´ˆ | 50MB |
| í…ìŠ¤íŠ¸ í´ë¦¬ë‹ | 30KB | 0.1ì´ˆ | 5MB |
| ì²­í‚¹ (heading_based) | 60ê°œ ì²­í¬ | 0.3ì´ˆ | 10MB |
| Qwen3 ì„ë² ë”© | 60ê°œ ì²­í¬ | **12ì´ˆ** | 500MB |
| FAISS ì‚½ì… | 60ê°œ ë²¡í„° | 0.05ì´ˆ | 20MB |
| FAISS ê²€ìƒ‰ | Top-5 | 0.01ì´ˆ | 5MB |
| GPT ë‹µë³€ ìƒì„± | 5ê°œ ì²­í¬ ì…ë ¥ | 3ì´ˆ | 10MB |
| **ì „ì²´ Ingestion** | 15í˜ì´ì§€ PDF | **15ì´ˆ** | 600MB |
| **RAG Query** | 1ê°œ ì§ˆë¬¸ | **3ì´ˆ** | 50MB |

**ë³‘ëª©**: Qwen3 ì„ë² ë”© (CPU ì¶”ë¡  ëŠë¦¼)
**í•´ê²°**: ë°°ì¹˜ ì„ë² ë”©, GPU ì‚¬ìš©, ë˜ëŠ” OpenAI Embeddings API

---

## ì„¤ì¹˜ ë° ì‹¤í–‰

### 1. í™˜ê²½ ìš”êµ¬ì‚¬í•­

- **Python**: 3.9 ì´ìƒ
- **OS**: Windows / Linux / macOS
- **RAM**: ìµœì†Œ 2GB (Qwen3 ì‚¬ìš© ì‹œ 4GB ê¶Œì¥)
- **Disk**: 2GB (ëª¨ë¸ ìºì‹œ í¬í•¨)

### 2. ì„¤ì¹˜

```bash
# 1. í”„ë¡œì íŠ¸ í´ë¡ 
cd C:\Users\user\OneDrive\ë°”íƒ• í™”ë©´\ìµœì¢…í”„ë¡œì íŠ¸\CTRL_F\AI\chunking

# 2. ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. í•„ìˆ˜ ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# 4. ì„ íƒì  ì˜ì¡´ì„± (Qwen3 ì„ë² ë”© ì‚¬ìš© ì‹œ)
pip install langchain-huggingface sentence-transformers torch

# 5. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ì„ ì—´ì–´ OPENAI_API_KEY ë“± ì„¤ì •
```

### 3. ì‹¤í–‰

#### ë°©ë²• 1: FastAPI ì„œë²„ë§Œ ì‹¤í–‰

```bash
cd C:\Users\user\OneDrive\ë°”íƒ• í™”ë©´\ìµœì¢…í”„ë¡œì íŠ¸\CTRL_F\AI\chunking
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

ì ‘ì†: http://localhost:8000/docs (Swagger UI)

#### ë°©ë²• 2: Streamlit UI ì‹¤í–‰

```bash
# í„°ë¯¸ë„ 1: FastAPI ì„œë²„
cd C:\Users\user\OneDrive\ë°”íƒ• í™”ë©´\ìµœì¢…í”„ë¡œì íŠ¸\CTRL_F\AI\chunking
uvicorn app.main:app --reload

# í„°ë¯¸ë„ 2: Streamlit UI
cd C:\Users\user\OneDrive\ë°”íƒ• í™”ë©´\ìµœì¢…í”„ë¡œì íŠ¸\CTRL_F\AI\chunking
streamlit run app/ui/streamlit_app.py
```

ì ‘ì†: http://localhost:8501

### 4. í™˜ê²½ë³€ìˆ˜ ì„¤ì • (`.env`)

```bash
# ì„ë² ë”© ì„¤ì •
EMBEDDING_PROVIDER=qwen3  # dummy, qwen3, openai
EMBEDDING_DIM=384

# OpenAI ì„¤ì • (RAG ë‹µë³€ ìƒì„±ìš©)
ENABLE_OPENAI=true
OPENAI_API_KEY=sk-proj-...
OPENAI_MODEL=gpt-3.5-turbo

# API ì„¤ì •
API_BASE_URL=http://localhost:8000
```

### 5. ì‚¬ìš© ì˜ˆì‹œ

#### Streamlit UI ì‚¬ìš©

1. **ë¬¸ì„œ ì—…ë¡œë“œ** íƒ­:
   - PDF íŒŒì¼ ì—…ë¡œë“œ
   - ì²­í‚¹ ì „ëµ ì„ íƒ: `heading_based`
   - `max_chars`: 2000
   - "ì²˜ë¦¬ ì‹œì‘" í´ë¦­

2. **ë¬¸ì„œ ê²€ìƒ‰** íƒ­:
   - ê²€ìƒ‰ì–´ ì…ë ¥: "êµ¬ë§¤ ìš”ì²­ì„œ"
   - Top-K: 5
   - "ê²€ìƒ‰" í´ë¦­
   - ê²°ê³¼: ìœ ì‚¬ë„ ì ìˆ˜ + ì²­í¬ í…ìŠ¤íŠ¸

3. **ì§ˆë¬¸í•˜ê¸°** íƒ­:
   - ì§ˆë¬¸ ì…ë ¥: "ì£¼ì‹ ì†Œê° ë°©ë²•ì´ ë­ì•¼?"
   - LLM íƒ€ì…: `OpenAI`
   - "ì§ˆë¬¸í•˜ê¸°" í´ë¦­
   - ê²°ê³¼: GPT ë‹µë³€ + ê²€ìƒ‰ëœ ì²­í¬

#### API ì§ì ‘ í˜¸ì¶œ

```bash
# 1. íŒŒì¼ ì—…ë¡œë“œ
curl -X POST "http://localhost:8000/api/v1/ingest/file" \
  -F "file=@data/êµ¬ë§¤ì—…ë¬´ì²˜ë¦¬ê·œì •.pdf" \
  -F "chunk_strategy=heading_based" \
  -F "max_chars=2000"

# 2. RAG ë‹µë³€ ìƒì„±
curl -X POST "http://localhost:8000/api/v1/rag/answer" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "ì£¼ì‹ ì†Œê° ë°©ë²•",
    "top_k": 5,
    "llm_type": "openai",
    "max_tokens": 500
  }'
```

---

## í–¥í›„ ê°œì„  ë°©í–¥

### 1. ë‹¨ê¸° ê°œì„  (1ê°œì›”)

| ê°œì„  í•­ëª© | í˜„ì¬ ìƒíƒœ | ëª©í‘œ | ìš°ì„ ìˆœìœ„ |
|---------|---------|------|---------|
| **DOCX/PPTX íŒŒì„œ** | Skeleton | ì™„ì „ êµ¬í˜„ | ğŸ”´ ë†’ìŒ |
| **HWP íŒŒì„œ Python 3 í˜¸í™˜** | ì„¤ì¹˜ ì‹¤íŒ¨ | ëŒ€ì²´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²€í†  | ğŸŸ¡ ì¤‘ê°„ |
| **GPU ê°€ì†** | CPU ì „ìš© | FAISS GPU, Torch CUDA | ğŸŸ¡ ì¤‘ê°„ |
| **ë°°ì¹˜ ì„ë² ë”©** | ê°œë³„ ì„ë² ë”© | ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì†ë„ í–¥ìƒ | ğŸŸ¢ ë‚®ìŒ |

### 2. ì¤‘ê¸° ê°œì„  (3ê°œì›”)

| ê°œì„  í•­ëª© | ì„¤ëª… | ê¸°ëŒ€ íš¨ê³¼ |
|---------|------|----------|
| **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰** | Keyword (BM25) + Semantic (Vector) | ê²€ìƒ‰ ì •í™•ë„ 15-20% í–¥ìƒ |
| **ì²­í¬ ì¬ìˆœìœ„** | Cross-Encoderë¡œ ê²€ìƒ‰ ê²°ê³¼ ì¬ì •ë ¬ | Hit@1 ì •í™•ë„ 80% â†’ 90% |
| **ë¬¸ì„œ ë²„ì „ ê´€ë¦¬** | ë™ì¼ ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì‹œ ë²„ì „ ì¶”ì  | ë³€ê²½ ì´ë ¥ ì¶”ì  |
| **ì‚¬ìš©ì í”¼ë“œë°± ë£¨í”„** | ë‹µë³€ í‰ê°€ (ğŸ‘/ğŸ‘) ìˆ˜ì§‘ | ì§€ì†ì  í’ˆì§ˆ ê°œì„  |

### 3. ì¥ê¸° ê°œì„  (6ê°œì›”+)

| ê°œì„  í•­ëª© | ì„¤ëª… | ê¸°ìˆ  ìŠ¤íƒ |
|---------|------|----------|
| **ë©€í‹°ëª¨ë‹¬ ì§€ì›** | ì´ë¯¸ì§€, í‘œ, ê·¸ë˜í”„ ì´í•´ | GPT-4V, LLaVA |
| **ëŒ€í™”í˜• RAG** | ë‹¤íšŒì°¨ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ | LangGraph, Memory |
| **ë„ë©”ì¸ íŠ¹í™” ëª¨ë¸** | ë²•ë¥ /ì˜ë£Œ ë¶„ì•¼ ì „ìš© ì„ë² ë”© | Fine-tuning Qwen3 |
| **ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸** | ë¬¸ì„œ ìˆ˜ì • ì‹œ ìë™ ì¬ì²˜ë¦¬ | File Watcher, Celery |
| **ë¶„ì‚° ì²˜ë¦¬** | ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ë³‘ë ¬ ì²˜ë¦¬ | Ray, Dask |
| **Kubernetes ë°°í¬** | í”„ë¡œë•ì…˜ ìŠ¤ì¼€ì¼ë§ | K8s, Helm |

### 4. ê¸°ìˆ  ë¶€ì±„ í•´ê²°

| í•­ëª© | í˜„ì¬ ë¬¸ì œ | í•´ê²° ë°©ì•ˆ |
|-----|---------|----------|
| **FAISS ì˜ì†í™”** | In-Memory (ì¬ì‹œì‘ ì‹œ ì†ì‹¤) | íŒŒì¼ ê¸°ë°˜ ì €ì¥ êµ¬í˜„ ì™„ë£Œ â†’ DB ì—°ë™ ê²€í†  |
| **ëª¨ë‹ˆí„°ë§ DB** | JSON íŒŒì¼ | PostgreSQL / MongoDB ì „í™˜ |
| **í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€** | ë‚®ìŒ | pytest ë‹¨ìœ„/í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„± |
| **ì—ëŸ¬ í•¸ë“¤ë§** | ì¼ë¶€ ëˆ„ë½ | ì „ì²´ íŒŒì´í”„ë¼ì¸ try-except ë³´ê°• |
| **ë¡œê¹…** | ê¸°ë³¸ ë¡œê¹… | êµ¬ì¡°í™”ëœ ë¡œê¹… (JSON) + ELK ìŠ¤íƒ |

---

## ê²°ë¡ 

**CTRL-F AI ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ**ì€ ë‹¤ì¤‘ í˜•ì‹ ë¬¸ì„œ íŒŒì‹±, ì˜ë¯¸ë¡ ì  ê²€ìƒ‰, RAG ë‹µë³€ ìƒì„±ì„ í†µí•©í•œ ì—”ë“œíˆ¬ì—”ë“œ AI ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### í•µì‹¬ ì„±ê³¼

1. **ë‹¤ì¤‘ í˜•ì‹ ì§€ì›**: PDF, HWP, DOCX, PPTX ë‹¨ì¼ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬
2. **ê³ í’ˆì§ˆ ê²€ìƒ‰**: Qwen3 ì„ë² ë”©ìœ¼ë¡œ ê²€ìƒ‰ ì •í™•ë„ 2.5ë°° í–¥ìƒ (30% â†’ 75%)
3. **ì§€ëŠ¥í˜• ì²­í‚¹**: í•œêµ­ì–´ ë²•ë¥  ë¬¸ì„œ ì œëª© íƒì§€ ë° êµ¬ì¡° ë³´ì¡´
4. **ìì—°ì–´ ë‹µë³€**: OpenAI GPT í†µí•©ìœ¼ë¡œ ì‹¤ìš©ì ì¸ ì§ˆì˜ì‘ë‹µ ì œê³µ
5. **ì „ì²˜ë¦¬ ëª¨ë‹ˆí„°ë§**: 8ë‹¨ê³„ ë©”íŠ¸ë¦­ìœ¼ë¡œ í’ˆì§ˆ ì¶”ì 

### íƒ€ í”„ë¡œì íŠ¸ ëŒ€ë¹„ ì°¨ë³„ì 

- **langflow_ì†Œí˜„**: Langflow ëŒ€ì‹  FastAPIë¡œ ì„¸ë°€í•œ ì œì–´
- **langflow_ì„¸í¬**: ë‹¤ì¤‘ í˜•ì‹ íŒŒì„œ ê³„ìŠ¹ + ì²­í‚¹ ì „ëµ 3ë°° í™•ì¥

### í™œìš© ê°€ì¹˜

- **ê¸°ì—… ë¬¸ì„œ ê²€ìƒ‰**: ì‚¬ê·œ, ê·œì •, ê³„ì•½ì„œ ë“± ë²•ë¥  ë¬¸ì„œ ê²€ìƒ‰
- **ê³ ê° ì§€ì›**: FAQ, ë§¤ë‰´ì–¼ ê¸°ë°˜ ìë™ ì‘ë‹µ
- **ì—°êµ¬ ì§€ì›**: ë…¼ë¬¸, ë³´ê³ ì„œ ê²€ìƒ‰ ë° ìš”ì•½

---

**ì‘ì„±ì¼**: 2025-01-20
**ì‘ì„±ì**: Claude Code (Anthropic)
**í”„ë¡œì íŠ¸ ê²½ë¡œ**: `C:\Users\user\OneDrive\ë°”íƒ• í™”ë©´\ìµœì¢…í”„ë¡œì íŠ¸\CTRL_F\AI\chunking`
**ë²„ì „**: 1.0.0
