# streamlit_app.py
import sys
import os
import streamlit as st
import requests
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from typing import Optional, Dict, Any
from pathlib import Path
import tempfile

# ===============================
# core ëª¨ë“ˆ import ê²½ë¡œ ì„¤ì •
# ===============================
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))
from core.cleaner import clean_text
from core.chunker import chunk_text, chunk_by_paragraphs, chunk_by_headings
from core.hwp_converter import convert_hwp_to_text
from core.vector_store import get_vector_store
from core.embedder import embed_texts

# ===============================
# í•œê¸€ í°íŠ¸ ì„¤ì • (Windows)
# ===============================
try:
    font_path = "C:/Windows/Fonts/malgun.ttf"
    if os.path.exists(font_path):
        font_prop = fm.FontProperties(fname=font_path)
        plt.rcParams['font.family'] = font_prop.get_name()
        plt.rcParams['axes.unicode_minus'] = False
    else:
        plt.rcParams['font.family'] = 'Malgun Gothic'
except Exception as e:
    print("í°íŠ¸ ì„¤ì • ì˜¤ë¥˜:", e)
    plt.rcParams['font.family'] = 'sans-serif'

# ===============================
# API ê¸°ë³¸ URL
# ===============================
API_BASE_URL = os.getenv("API_BASE_URL", "http://localhost:8000")

# ===============================
# Streamlit í˜ì´ì§€ ì„¤ì •
# ===============================
st.set_page_config(
    page_title="ë¬¸ì„œ ê²€ìƒ‰ & HWP ì „ì²˜ë¦¬ ì‹œìŠ¤í…œ",
    page_icon="ğŸ“š",
    layout="wide"
)

# ===============================
# í—¬ìŠ¤ì²´í¬
# ===============================
def check_system_health() -> Dict[str, Any]:
    try:
        response = requests.get(f"{API_BASE_URL}/api/v1/rag/health", timeout=30)
        if response.ok:
            return response.json()
        return {"status": "unhealthy", "message": "API ì—°ê²° ì‹¤íŒ¨"}
    except Exception as e:
        return {"status": "error", "message": f"{str(e)}"}

# ===============================
# ë²¡í„° ì´ˆê¸°í™”
# ===============================
def reset_vector_store():
    try:
        response = requests.post(f"{API_BASE_URL}/api/v1/rag/reset", timeout=60)
        if response.ok:
            return response.json()
        else:
            st.error(f"ë²¡í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {response.text}")
            return None
    except Exception as e:
        st.error(f"ë²¡í„° ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
        return None

# ===============================
# API ì—…ë¡œë“œ/ê²€ìƒ‰/RAG
# ===============================
def upload_file(file, chunk_strategy: str, max_chars: int, overlap_chars: int, use_ocr: bool):
    try:
        files = {"file": (file.name, file, file.type)}
        data = {
            "chunk_strategy": chunk_strategy,
            "max_chars": max_chars,
            "overlap_chars": overlap_chars,
            "use_ocr_fallback": use_ocr
        }
        response = requests.post(
            f"{API_BASE_URL}/api/v1/ingest/file",
            files=files,
            data=data,
            timeout=600
        )
        if response.ok:
            return response.json()
        else:
            st.error(f"ì—…ë¡œë“œ ì‹¤íŒ¨: {response.text}")
            return None
    except Exception as e:
        st.error(f"ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return None

def search_documents(query: str, top_k: int):
    try:
        response = requests.post(
            f"{API_BASE_URL}/api/v1/rag/query",
            json={"query": query, "top_k": top_k, "include_context": True},
            timeout=60
        )
        if response.ok:
            return response.json()
        else:
            st.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {response.text}")
            return None
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return None

def generate_answer(query: str, top_k: int, max_tokens: int, llm_type: Optional[str] = None):
    try:
        payload = {"query": query, "top_k": top_k, "max_tokens": max_tokens}
        if llm_type:
            payload["llm_type"] = llm_type

        response = requests.post(
            f"{API_BASE_URL}/api/v1/rag/answer",
            json=payload,
            timeout=120
        )
        if response.ok:
            return response.json()
        else:
            st.error(f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {response.text}")
            return None
    except Exception as e:
        st.error(f"ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return None

# ===============================
# ë²¡í„° ìŠ¤í† ì–´ì— ë¡œì»¬ ì²­í¬ ì‚½ì… (FAISS í˜¸í™˜)
# ===============================
def insert_chunks_to_vector_store(ingest_id: str, chunks_list):
    try:
        vs = get_vector_store(dim=384)
        vectors = embed_texts(chunks_list)
        # ë‹¨ì¼ ë²¡í„° ë°˜ë³µ ëŒ€ì‹  í•œ ë²ˆì— add_vectors í˜¸ì¶œ
        metadatas = [{"ingest_id": ingest_id, "chunk_index": i, "text": chunks_list[i]} for i in range(len(chunks_list))]
        vs.add_vectors(vectors, metadatas)
        return len(chunks_list)
    except Exception as e:
        st.error(f"ë²¡í„° ì‚½ì… ì˜¤ë¥˜: {str(e)}")
        return 0

# ===============================
# ë¡œì»¬ ì „ì²˜ë¦¬/ì²­í‚¹ (HWP ì§€ì›)
# ===============================
def process_file_local(file, chunk_strategy: str, max_chars: int, overlap_chars: int):
    try:
        file_ext = os.path.splitext(file.name)[1].lower()
        raw_text = ""

        if file_ext == ".pdf":
            from PyPDF2 import PdfReader
            reader = PdfReader(file)
            raw_text = "\n".join([p.extract_text() or "" for p in reader.pages])
        elif file_ext in [".txt", ".md"]:
            raw_text = file.read().decode("utf-8", errors="ignore")
        elif file_ext == ".hwp":
            tmp_path = None
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".hwp") as tmp:
                    tmp.write(file.read())
                    tmp_path = tmp.name
                raw_text = convert_hwp_to_text(tmp_path)
            finally:
                if tmp_path and os.path.exists(tmp_path):
                    os.remove(tmp_path)
        else:
            st.warning(f"{file_ext} í˜•ì‹ì€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. PDF/TXT/HWPë§Œ ê°€ëŠ¥.")
            return None

        cleaned_text = clean_text(raw_text)

        if chunk_strategy == "character_window":
            chunks_list = chunk_text(cleaned_text, max_chars=max_chars, overlap_chars=overlap_chars)
        elif chunk_strategy == "paragraph_based":
            chunks_list = chunk_by_paragraphs([{"section": "ì „ì²´", "content": cleaned_text}], max_chars=max_chars)
        elif chunk_strategy == "heading_based":
            chunks_list = chunk_by_headings([{"section": "ì „ì²´", "content": cleaned_text}], max_chars=max_chars)
        else:
            chunks_list = [cleaned_text]

        chunk_lengths = [len(c) for c in chunks_list]

        ingest_id = "local_" + file.name
        # ë²¡í„° ìŠ¤í† ì–´ ì‚½ì…
        inserted_count = insert_chunks_to_vector_store(ingest_id, chunks_list)

        return {
            "ingest_id": ingest_id,
            "status": "OK",
            "num_chunks": len(chunks_list),
            "raw_text_len": len(raw_text),
            "cleaned_text_len": len(cleaned_text),
            "chunk_texts": chunks_list,
            "chunk_lengths": chunk_lengths,
            "inserted_chunks": inserted_count,
            "cleaned_text": cleaned_text
        }

    except Exception as e:
        st.error(f"ë¡œì»¬ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return None

# ===============================
# Streamlit UI
# ===============================
def main():
    st.title("ğŸ“š ë¬¸ì„œ ê²€ìƒ‰ & HWP ì „ì²˜ë¦¬ ì‹œìŠ¤í…œ")

    # -------------------------
    # ì‚¬ì´ë“œë°”
    # -------------------------
    with st.sidebar:
        st.header("âš™ï¸ ì‹œìŠ¤í…œ ìƒíƒœ")
        if st.button("ìƒíƒœ ìƒˆë¡œê³ ì¹¨"):
            st.experimental_rerun()

        health = check_system_health()
        status_color = {"healthy":"ğŸŸ¢","degraded":"ğŸŸ¡","unhealthy":"ğŸ”´","error":"âš«"}
        st.write(f"{status_color.get(health.get('status','error'),'âš«')} **{health.get('status','unknown').upper()}**")
        st.write(f"ë©”ì‹œì§€: {health.get('message','N/A')}")
        if health.get("status") in ["healthy","degraded"]:
            st.metric("ë²¡í„° ê°œìˆ˜", health.get("total_vectors",0))
            st.write(f"ì„ë² ë”: {'âœ…' if health.get('embedder_available') else 'âŒ'}")
            st.write(f"ë²¡í„°ìŠ¤í† ì–´: {'âœ…' if health.get('vector_store_available') else 'âŒ'}")
            st.write(f"LLM: {'âœ…' if health.get('llm_available') else 'âŒ'} ({health.get('llm_type','N/A')})")
        st.divider()
        st.caption(f"API: {API_BASE_URL}")

    # -------------------------
    # íƒ­1: íŒŒì¼ ì—…ë¡œë“œ
    # -------------------------
    tab1, tab2, tab3 = st.tabs(["ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ” ë¬¸ì„œ ê²€ìƒ‰", "ğŸ’¬ ì§ˆë¬¸í•˜ê¸°"])
    with tab1:
        st.header("íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬")
        uploaded_file = st.file_uploader("ë¬¸ì„œ íŒŒì¼ ì„ íƒ", type=["pdf","txt","hwp"])

        col1, col2 = st.columns(2)
        with col1:
            chunk_strategy = st.selectbox("ì²­í‚¹ ì „ëµ", ["character_window","paragraph_based","heading_based"])
            max_chars = st.slider("ìµœëŒ€ ì²­í¬ í¬ê¸°", 500, 3000, 1000, 100)
        with col2:
            overlap_chars = st.slider("ì²­í¬ ê²¹ì¹¨", 0, 500, 200, 50)
            use_local = st.checkbox("ë¡œì»¬ ì „ì²˜ë¦¬ ì‚¬ìš©", value=True)

        if uploaded_file and st.button("íŒŒì¼ ì²˜ë¦¬ ì‹œì‘"):
            with st.spinner("íŒŒì¼ ì²˜ë¦¬ ì¤‘..."):
                if use_local:
                    result = process_file_local(uploaded_file, chunk_strategy, max_chars, overlap_chars)
                else:
                    result = upload_file(uploaded_file, chunk_strategy, max_chars, overlap_chars, use_ocr=True)

            if result:
                st.success(f"âœ… ì²˜ë¦¬ ì™„ë£Œ! (Ingest ID: {result['ingest_id']})")
                col1, col2, col3, col4, col5 = st.columns(5)
                col1.metric("ìƒíƒœ", result.get("status","N/A"))
                col2.metric("ì²­í¬ ê°œìˆ˜", result.get("num_chunks",0))
                col3.metric("ì›ë³¸ í…ìŠ¤íŠ¸", f"{result.get('raw_text_len',0):,} ì")
                col4.metric("ì •ì œ í›„", f"{result.get('cleaned_text_len',0):,} ì")
                col5.metric("ë²¡í„° ì‚½ì… ì™„ë£Œ", result.get("inserted_chunks",0))

                st.subheader("ğŸ“ ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸")
                preview_text = result.get("cleaned_text","")[:20000]
                st.text_area("ì „ì²˜ë¦¬ ê²°ê³¼ (ìµœëŒ€ 2ë§Œì)", value=preview_text, height=300)

                if "chunk_texts" in result:
                    st.subheader("ğŸ“š ì²­í¬ë³„ í…ìŠ¤íŠ¸")
                    for i, chunk_text in enumerate(result["chunk_texts"]):
                        with st.expander(f"ì²­í¬ {i+1} (ê¸¸ì´: {len(chunk_text)})"):
                            st.text_area(f"ì²­í¬ {i+1}", value=chunk_text, height=200)

    # -------------------------
    # íƒ­2: ë¬¸ì„œ ê²€ìƒ‰
    # -------------------------
    with tab2:
        st.header("ë¬¸ì„œ ê²€ìƒ‰")
        search_query = st.text_input("ê²€ìƒ‰ ì§ˆë¬¸")
        search_top_k = st.slider("ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜",1,20,5)
        if search_query and st.button("ê²€ìƒ‰"):
            with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                results = search_documents(search_query, search_top_k)
            if results:
                st.success(f"âœ… {results.get('total_retrieved',0)}ê°œ ê²°ê³¼ ë°œê²¬")
                for i, chunk in enumerate(results.get("retrieved_chunks",[])):
                    with st.expander(f"ê²°ê³¼ {i+1} - {chunk.get('file_name','N/A')}"):
                        st.write(chunk.get("text",""))

    # -------------------------
    # íƒ­3: ì§ˆë¬¸í•˜ê¸°
    # -------------------------
    with tab3:
        st.header("ì§ˆë¬¸í•˜ê¸° (RAG)")
        rag_query = st.text_area("ì§ˆë¬¸ ì…ë ¥")
        col1, col2 = st.columns(2)
        with col1:
            rag_top_k = st.slider("ì°¸ì¡° ë¬¸ì„œ ê°œìˆ˜", 1, 10, 5)
        with col2:
            rag_max_tokens = st.slider("ìµœëŒ€ ìƒì„± í† í°", 100, 2000, 500, 100)
        rag_llm_type = st.selectbox("LLM íƒ€ì…", ["auto","mock","openai"])
        if rag_query and st.button("ë‹µë³€ ìƒì„±"):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                llm_type_param = None if rag_llm_type=="auto" else rag_llm_type
                answer_result = generate_answer(rag_query, rag_top_k, rag_max_tokens, llm_type_param)
            if answer_result:
                st.success("âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ")
                st.info(f"ğŸ¤– ì‚¬ìš©ëœ LLM: {answer_result.get('llm_type','N/A')}")
                st.subheader("ğŸ’¡ ë‹µë³€")
                st.markdown(answer_result.get("answer","ë‹µë³€ ì—†ìŒ"))
                st.subheader("ğŸ“„ ì°¸ì¡° ë¬¸ì„œ")
                chunks = answer_result.get("retrieved_chunks", [])
                if chunks:
                    df_data = [
                        {"ìˆœìœ„":i+1,"íŒŒì¼ëª…":c.get("file_name","N/A"),"ì²­í¬":c.get("chunk_index",0),
                         "ìœ ì‚¬ë„":f"{c.get('score',0):.4f}"} for i,c in enumerate(chunks)
                    ]
                    st.dataframe(pd.DataFrame(df_data), use_container_width=True)
                    for i, chunk in enumerate(chunks):
                        with st.expander(f"ìƒì„¸ ë‚´ìš© {i+1}"):
                            st.write(chunk.get("text",""))

if __name__ == "__main__":
    main()
