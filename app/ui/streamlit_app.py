"""
Streamlit UI - ë¬¸ì„œ ê²€ìƒ‰ ë° RAG ì‹œìŠ¤í…œ

ì‹¤í–‰ ë°©ë²•:
    streamlit run app/ui/streamlit_app.py

ê¸°ëŠ¥:
1. íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬
2. ë¬¸ì„œ ê²€ìƒ‰
3. RAG ì§ˆë¬¸-ë‹µë³€
4. ì²˜ë¦¬ í†µê³„ ì‹œê°í™”
"""

import streamlit as st
import requests
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from typing import Optional, Dict, Any
import os

# í•œê¸€ í°íŠ¸ ì„¤ì • (Windows)
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# API ê¸°ë³¸ URL
API_BASE_URL = os.getenv("API_BASE_URL", "http://localhost:8000")

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ",
    page_icon="ğŸ“š",
    layout="wide"
)


def check_system_health() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ í—¬ìŠ¤ì²´í¬"""
    try:
        response = requests.get(f"{API_BASE_URL}/api/v1/rag/health", timeout=5)
        if response.ok:
            return response.json()
        return {"status": "unhealthy", "message": "API ì—°ê²° ì‹¤íŒ¨"}
    except Exception as e:
        return {"status": "error", "message": str(e)}


def upload_file(file, chunk_strategy: str, max_chars: int, overlap_chars: int, use_ocr: bool):
    """íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬"""
    try:
        files = {"file": (file.name, file, file.type)}
        data = {
            "chunk_strategy": chunk_strategy,
            "max_chars": max_chars,
            "overlap_chars": overlap_chars,
            "use_ocr_fallback": use_ocr
        }
        response = requests.post(
            f"{API_BASE_URL}/api/v1/ingest/file",
            files=files,
            data=data,
            timeout=300
        )
        if response.ok:
            return response.json()
        else:
            st.error(f"ì—…ë¡œë“œ ì‹¤íŒ¨: {response.text}")
            return None
    except Exception as e:
        st.error(f"ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return None


def search_documents(query: str, top_k: int):
    """ë¬¸ì„œ ê²€ìƒ‰"""
    try:
        response = requests.post(
            f"{API_BASE_URL}/api/v1/rag/query",
            json={"query": query, "top_k": top_k, "include_context": True},
            timeout=30
        )
        if response.ok:
            return response.json()
        else:
            st.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {response.text}")
            return None
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return None


def generate_answer(query: str, top_k: int, max_tokens: int, llm_type: Optional[str] = None):
    """RAG ë‹µë³€ ìƒì„±"""
    try:
        payload = {
            "query": query,
            "top_k": top_k,
            "max_tokens": max_tokens
        }
        if llm_type:
            payload["llm_type"] = llm_type

        response = requests.post(
            f"{API_BASE_URL}/api/v1/rag/answer",
            json=payload,
            timeout=60
        )
        if response.ok:
            return response.json()
        else:
            st.error(f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {response.text}")
            return None
    except Exception as e:
        st.error(f"ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return None


def main():
    st.title("ğŸ“š ë¬¸ì„œ ê²€ìƒ‰ ë° RAG ì‹œìŠ¤í…œ")

    # ì‚¬ì´ë“œë°”: ì‹œìŠ¤í…œ ìƒíƒœ
    with st.sidebar:
        st.header("âš™ï¸ ì‹œìŠ¤í…œ ìƒíƒœ")

        if st.button("ìƒíƒœ ìƒˆë¡œê³ ì¹¨"):
            st.rerun()

        health = check_system_health()

        status_color = {
            "healthy": "ğŸŸ¢",
            "degraded": "ğŸŸ¡",
            "unhealthy": "ğŸ”´",
            "error": "âš«"
        }

        st.write(f"{status_color.get(health.get('status', 'error'), 'âš«')} **{health.get('status', 'unknown').upper()}**")
        st.write(f"ë©”ì‹œì§€: {health.get('message', 'N/A')}")

        if health.get("status") == "healthy" or health.get("status") == "degraded":
            st.metric("ë²¡í„° ê°œìˆ˜", health.get("total_vectors", 0))
            st.write(f"ì„ë² ë”: {'âœ…' if health.get('embedder_available') else 'âŒ'}")
            st.write(f"ë²¡í„°ìŠ¤í† ì–´: {'âœ…' if health.get('vector_store_available') else 'âŒ'}")
            st.write(f"LLM: {'âœ…' if health.get('llm_available') else 'âŒ'} ({health.get('llm_type', 'N/A')})")

        st.divider()
        st.caption(f"API: {API_BASE_URL}")

    # ë©”ì¸ íƒ­
    tab1, tab2, tab3 = st.tabs(["ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ” ë¬¸ì„œ ê²€ìƒ‰", "ğŸ’¬ ì§ˆë¬¸í•˜ê¸°"])

    # íƒ­1: íŒŒì¼ ì—…ë¡œë“œ
    with tab1:
        st.header("íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬")

        uploaded_file = st.file_uploader(
            "ë¬¸ì„œ íŒŒì¼ ì„ íƒ",
            type=["pdf", "hwp", "docx", "pptx"],
            help="PDF, HWP, DOCX, PPTX íŒŒì¼ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        )

        col1, col2 = st.columns(2)

        with col1:
            chunk_strategy = st.selectbox(
                "ì²­í‚¹ ì „ëµ",
                ["character_window", "paragraph_based", "heading_based"],
                help="character_window: ê³ ì • í¬ê¸° ìœˆë„ìš°, paragraph_based: ë¬¸ë‹¨ ê¸°ë°˜, heading_based: ì œëª© ê¸°ë°˜"
            )
            max_chars = st.slider("ìµœëŒ€ ì²­í¬ í¬ê¸°", 500, 3000, 1000, 100)

        with col2:
            overlap_chars = st.slider("ì²­í¬ ê²¹ì¹¨", 0, 500, 200, 50)
            use_ocr = st.checkbox("OCR í´ë°± ì‚¬ìš©", value=True, help="í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ OCR ì‚¬ìš©")

        if uploaded_file is not None:
            if st.button("íŒŒì¼ ì²˜ë¦¬ ì‹œì‘", type="primary"):
                with st.spinner("íŒŒì¼ ì²˜ë¦¬ ì¤‘..."):
                    result = upload_file(uploaded_file, chunk_strategy, max_chars, overlap_chars, use_ocr)

                if result:
                    st.success(f"âœ… ì²˜ë¦¬ ì™„ë£Œ! (Ingest ID: {result['ingest_id']})")

                    col1, col2, col3, col4 = st.columns(4)
                    col1.metric("ìƒíƒœ", result.get("status", "N/A"))
                    col2.metric("ì²­í¬ ê°œìˆ˜", result.get("num_chunks", 0))
                    col3.metric("ì›ë³¸ í…ìŠ¤íŠ¸", f"{result.get('raw_text_len', 0):,} ì")
                    col4.metric("ì •ì œ í›„", f"{result.get('cleaned_text_len', 0):,} ì")

                    # ëª¨ë‹ˆí„°ë§ ë°ì´í„° ì‹œê°í™”
                    if "monitoring" in result:
                        st.subheader("ğŸ“Š ì²˜ë¦¬ í†µê³„")
                        monitoring = result["monitoring"]

                        # ì²­í¬ ê¸¸ì´ ë¶„í¬
                        if "chunking" in monitoring and "chunk_lengths" in monitoring["chunking"]:
                            chunk_lengths = monitoring["chunking"]["chunk_lengths"]

                            fig, ax = plt.subplots(figsize=(10, 4))
                            ax.hist(chunk_lengths, bins=20, edgecolor='black', alpha=0.7)
                            ax.set_xlabel("ì²­í¬ ê¸¸ì´ (ì)")
                            ax.set_ylabel("ë¹ˆë„")
                            ax.set_title("ì²­í¬ ê¸¸ì´ ë¶„í¬")
                            ax.axvline(max_chars, color='red', linestyle='--', label=f'max_chars={max_chars}')
                            ax.legend()
                            st.pyplot(fig)

                            # í†µê³„ ì •ë³´
                            col1, col2, col3, col4 = st.columns(4)
                            col1.metric("í‰ê· ", f"{monitoring['chunking'].get('chunk_len_avg', 0):.1f}")
                            col2.metric("ìµœì†Œ", monitoring['chunking'].get('chunk_len_min', 0))
                            col3.metric("ìµœëŒ€", monitoring['chunking'].get('chunk_len_max', 0))
                            col4.metric("í‘œì¤€í¸ì°¨", f"{monitoring['chunking'].get('chunk_len_std', 0):.1f}")

    # íƒ­2: ë¬¸ì„œ ê²€ìƒ‰
    with tab2:
        st.header("ë¬¸ì„œ ê²€ìƒ‰")

        search_query = st.text_input("ê²€ìƒ‰ ì§ˆë¬¸", placeholder="ì˜ˆ: êµ¬ë§¤ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?")
        search_top_k = st.slider("ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜", 1, 20, 5)

        if st.button("ê²€ìƒ‰", type="primary") and search_query:
            with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                results = search_documents(search_query, search_top_k)

            if results:
                st.success(f"âœ… {results.get('total_retrieved', 0)}ê°œ ê²°ê³¼ ë°œê²¬")

                for i, chunk in enumerate(results.get("retrieved_chunks", [])):
                    with st.expander(f"**ê²°ê³¼ {i+1}** - {chunk.get('file_name', 'N/A')} (ìœ ì‚¬ë„: {chunk.get('score', 0):.3f})"):
                        st.write(f"**ì¶œì²˜:** {chunk.get('file_name', 'N/A')}")
                        st.write(f"**ì²­í¬ ì¸ë±ìŠ¤:** {chunk.get('chunk_index', 0)}")
                        st.write(f"**ì²­í‚¹ ì „ëµ:** {chunk.get('strategy', 'N/A')}")
                        st.write(f"**ìœ ì‚¬ë„ ì ìˆ˜:** {chunk.get('score', 0):.4f} (ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬)")
                        st.divider()
                        st.write(chunk.get("text", "í…ìŠ¤íŠ¸ ì—†ìŒ"))

    # íƒ­3: ì§ˆë¬¸í•˜ê¸° (RAG)
    with tab3:
        st.header("ì§ˆë¬¸í•˜ê¸° (RAG)")

        rag_query = st.text_area(
            "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
            placeholder="ì˜ˆ: êµ¬ë§¤ì—…ë¬´ì²˜ë¦¬ê·œì •ì— ë”°ë¥´ë©´ êµ¬ë§¤ ìš”ì²­ì€ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?",
            height=100
        )

        col1, col2, col3 = st.columns(3)
        with col1:
            rag_top_k = st.slider("ì°¸ì¡° ë¬¸ì„œ ê°œìˆ˜", 1, 10, 5, key="rag_top_k")
        with col2:
            rag_max_tokens = st.slider("ìµœëŒ€ ìƒì„± í† í°", 100, 2000, 500, 100, key="rag_max_tokens")
        with col3:
            rag_llm_type = st.selectbox(
                "LLM íƒ€ì…",
                ["auto", "mock", "openai"],
                help="auto: ìë™ ì„ íƒ, mock: ê°œë°œìš© ë”ë¯¸, openai: OpenAI GPT (ENABLE_OPENAI=true í•„ìš”)"
            )

        if st.button("ë‹µë³€ ìƒì„±", type="primary") and rag_query:
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                llm_type_param = None if rag_llm_type == "auto" else rag_llm_type
                answer_result = generate_answer(rag_query, rag_top_k, rag_max_tokens, llm_type_param)

            if answer_result:
                st.success("âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ")

                # LLM ì •ë³´
                st.info(f"ğŸ¤– ì‚¬ìš©ëœ LLM: **{answer_result.get('llm_type', 'N/A')}**")

                # ë‹µë³€ í‘œì‹œ
                st.subheader("ğŸ’¡ ë‹µë³€")
                st.markdown(answer_result.get("answer", "ë‹µë³€ ì—†ìŒ"))

                st.divider()

                # ì°¸ì¡° ë¬¸ì„œ
                st.subheader("ğŸ“„ ì°¸ì¡° ë¬¸ì„œ")
                chunks = answer_result.get("retrieved_chunks", [])

                if chunks:
                    # ìœ ì‚¬ë„ í…Œì´ë¸”
                    df_data = []
                    for i, chunk in enumerate(chunks):
                        df_data.append({
                            "ìˆœìœ„": i + 1,
                            "íŒŒì¼ëª…": chunk.get("file_name", "N/A"),
                            "ì²­í¬": chunk.get("chunk_index", 0),
                            "ìœ ì‚¬ë„": f"{chunk.get('score', 0):.4f}"
                        })

                    df = pd.DataFrame(df_data)
                    st.dataframe(df, use_container_width=True)

                    # ê° ì²­í¬ ìƒì„¸
                    for i, chunk in enumerate(chunks):
                        with st.expander(f"ìƒì„¸ ë‚´ìš© {i+1}"):
                            st.write(chunk.get("text", "í…ìŠ¤íŠ¸ ì—†ìŒ"))


if __name__ == "__main__":
    main()
