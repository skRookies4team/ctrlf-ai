# AI 채팅 서비스 성능 개선 보고서

## 1. 개요

### 1.1 프로젝트 배경
본 보고서는 CTRL+F AI 채팅 서비스의 질의응답 정확도 개선 과정을 기술합니다. 130개의 표준화된 Q&A 세트를 활용하여 체계적인 성능 측정 및 개선을 수행하였습니다.

### 1.2 테스트 목표
- 사내 정책/규정 관련 질문에 대한 정확한 의도 분류
- RAG(Retrieval-Augmented Generation) 기반 근거 있는 답변 제공
- 템플릿 폴백 응답 최소화

---

## 2. 테스트 환경

### 2.1 시스템 구성
| 구성 요소 | 상세 |
|-----------|------|
| 플랫폼 | Windows 11 (MINGW64) |
| Python | 3.x (Anaconda) |
| 웹 프레임워크 | FastAPI + Uvicorn |
| 벡터 DB | Milvus (RAGFlow 연동) |
| LLM | OpenAI GPT 기반 |

### 2.2 테스트 데이터셋
- **파일**: `Q세트.csv` (130개 질문)
- **도메인 분포**:
  - 사규/복무/인사 (RUL): 30문항
  - 개인정보보호 (PIP): 20문항
  - 성희롱 방지 (SHP): 20문항
  - 직장내괴롭힘 (BHP): 20문항
  - 장애인식 (DEP): 20문항
  - 직무별 교육 (JOB): 20문항

### 2.3 측정 지표
| 지표 | 설명 | 목표 |
|------|------|------|
| GENERAL_CHAT 비율 | 일반 잡담으로 오분류된 비율 | 최소화 |
| RAG_INTERNAL 비율 | RAG 검색을 수행한 비율 | 최대화 |
| 소스 포함 비율 | 답변에 근거 문서가 포함된 비율 | 최대화 |
| 템플릿 폴백 | 고정 템플릿으로 응답한 건수 | 0건 |
| 평균 응답 시간 | API 응답 완료까지 소요 시간 | 참고용 |

---

## 3. 1차 테스트 결과 (Baseline)

### 3.1 테스트 일시
2025-12-23 (최초 측정)

### 3.2 결과 요약

#### 인텐트 분류 결과
| 인텐트 | 건수 | 비율 |
|--------|------|------|
| GENERAL_CHAT | 80 | 61.5% |
| POLICY_QA | 23 | 17.7% |
| EDUCATION_QA | 20 | 15.4% |
| INCIDENT_QA | 4 | 3.1% |
| SYSTEM_HELP | 2 | 1.5% |
| EDU_STATUS | 1 | 0.8% |

#### 라우팅 결과
| 라우트 | 건수 | 비율 |
|--------|------|------|
| LLM_ONLY | 82 | 63.1% |
| RAG_INTERNAL | 47 | 36.2% |
| MIXED_BACKEND_RAG | 1 | 0.8% |

#### 핵심 문제점
```
- GENERAL_CHAT 오분류: 61.5% (80/130건)
- 템플릿 폴백 응답: 79건 (60.8%)
- 소스 포함 답변: 37건 (28.5%)
- 평균 응답 시간: 1,484ms
```

### 3.3 문제 분석

**증상**: 사내 정책 관련 질문("연차 규정", "재택근무 절차" 등)이 일반 잡담(GENERAL_CHAT)으로 분류되어 RAG 검색 없이 LLM_ONLY로 처리됨

**영향**:
- RAG 기반 근거 제공 불가
- 동일한 템플릿 폴백 응답 반복
- 사용자 만족도 저하

---

## 4. 문제 원인 분석

### 4.1 분석 방법론

#### Step 1: 응답 시간 패턴 분석
```
빠른 응답 (< 20ms): 79건 → 전부 GENERAL_CHAT
느린 응답 (> 1초): 51건 → 정상 분류 (POLICY_QA 등)
```
- **인사이트**: 79건이 비정상적으로 빠른 응답 → 파이프라인 초기에 short-circuit 발생

#### Step 2: 응답 내용 분석
```
빠른 응답 템플릿:
"방금 답변이 도움 안 됐죠. 미안해요.
관련 정보가 충분하지 않아 정확한 답변이 어려웠어요.
문서를 인덱싱하면 그 기준으로만 답하게 만들게요."
```
- **인사이트**: Complaint Fast Path 템플릿과 일치 → 불만/욕설 감지 로직 오작동 의심

#### Step 3: 키워드 매칭 분석
```python
# COMPLAINT_KEYWORDS 분석
COMPLAINT_KEYWORDS = {
    "그지", "왜몰라", "뭐하", "답답", "짜증", ...,
    "대체왜", "못알아", "모르냐", "이게뭐야", "쓸모없", "뭐냐", "하",  # ← 문제 원인
}
```

### 4.2 근본 원인 (Root Cause)

**COMPLAINT_KEYWORDS에 "하" 포함**

| 원인 | 영향 |
|------|------|
| "하"는 한국어 동사의 기본 형태 | "~하나요?", "~해야", "~하고" 등 모든 질문에 매칭 |
| 불만 감지 의도로 추가됨 ("하..." 한숨 표현) | 정상 질문 79건이 불만으로 오탐지 |
| Intent 분류 이전에 실행됨 | RAG/LLM 호출 없이 즉시 템플릿 반환 |

#### 검증 결과
```python
# 130개 질문 중 "하" 포함 질문 수
"하" 포함 질문: 79개 (60.8%)
Complaint 매칭: 79개 (100% "하"로 매칭)
```

---

## 5. 반복 테스트 및 디버깅 과정

### 5.1 디버깅 여정 개요

1차 테스트 결과 분석 후, 근본 원인을 찾기까지 **4회의 반복 테스트**를 수행하였습니다. 각 테스트는 가설 검증 및 새로운 문제 발견에 기여하였습니다.

```
┌─────────────────────────────────────────────────────────────────────────┐
│  1차 테스트 → 문제 발견 (61.5% GENERAL_CHAT)                            │
│       ↓                                                                 │
│  [가설 1] IntentService POLICY_KEYWORDS 부족?                           │
│       ↓                                                                 │
│  2차 테스트 → 변화 없음 → 서버 미재시작 문제 발견                        │
│       ↓                                                                 │
│  3차 테스트 → 변화 없음 → __pycache__ 캐싱 문제 발견                    │
│       ↓                                                                 │
│  4차 테스트 → 변화 없음 → IntentService 정상 확인 → 다른 곳 문제!       │
│       ↓                                                                 │
│  [가설 2] Complaint Fast Path 오작동?                                   │
│       ↓                                                                 │
│  근본 원인 발견: COMPLAINT_KEYWORDS "하" 키워드                         │
│       ↓                                                                 │
│  5차 테스트 → 극적 개선 (0% GENERAL_CHAT)                               │
└─────────────────────────────────────────────────────────────────────────┘
```

### 5.2 2차 테스트: 가설 검증 실패 → 환경 문제 발견

#### 수행 내용
- `IntentService`의 `POLICY_KEYWORDS`를 126개로 확장
- GENERAL_CHAT 키워드 체크보다 POLICY_KEYWORDS 체크를 먼저 수행하도록 순서 변경

#### 결과
| 지표 | 1차 | 2차 | 변화 |
|------|-----|-----|------|
| GENERAL_CHAT | 61.5% | 61.5% | 없음 |
| RAG_INTERNAL | 36.2% | 36.2% | 없음 |

#### 발견 사항
```
❌ 코드 수정이 서버에 반영되지 않음
✅ 원인: 서버 재시작 없이 테스트 수행
```

**교훈**: FastAPI/Uvicorn은 기본적으로 hot-reload가 비활성화되어 있음

### 5.3 3차 테스트: 서버 재시작 후에도 변화 없음

#### 수행 내용
- Python 프로세스 종료 후 서버 재시작
- 동일 테스트 재수행

#### 결과
| 지표 | 1차 | 3차 | 변화 |
|------|-----|-----|------|
| GENERAL_CHAT | 61.5% | 60.8% | -0.7%p (미미) |
| RAG_INTERNAL | 36.2% | 36.9% | +0.7%p (미미) |

#### 발견 사항
```
❌ 서버 재시작만으로는 코드 변경이 적용되지 않음
✅ 원인: __pycache__ 디렉토리의 .pyc 바이트코드 캐시
```

**해결**: `find . -type d -name "__pycache__" -exec rm -rf {} +` 실행

### 5.4 4차 테스트: 결정적 단서 발견

#### 수행 내용
- 모든 `__pycache__` 삭제 후 서버 재시작
- 동일 테스트 재수행

#### 결과
| 지표 | 1차 | 4차 | 변화 |
|------|-----|-----|------|
| GENERAL_CHAT | 61.5% | 60.8% | -0.7%p (미미) |
| RAG_INTERNAL | 36.2% | 36.9% | +0.7%p (미미) |

#### 핵심 발견: IntentService 직접 테스트
```python
# IntentService 단위 테스트 결과
Q: "몇 번 이상 초과 결근하면 무단결근으로 처리되며..."
→ Intent: POLICY_QA  ✅ (정상)
→ Route: RAG_INTERNAL ✅ (정상)

# 그러나 서버 API 응답
→ Intent: GENERAL_CHAT ❌ (여전히 오류)
→ Route: LLM_ONLY ❌ (여전히 오류)
```

#### 결정적 인사이트
```
✅ IntentService 코드 자체는 정상 동작
❌ 서버 API 응답은 여전히 GENERAL_CHAT
→ IntentService 이전 단계에서 차단되고 있음!
```

이 발견이 **Complaint Fast Path** 조사로 이어졌고, 결국 "하" 키워드 버그를 발견하게 됨.

### 5.5 테스트 히스토리 요약

| 테스트 | 수행 내용 | GENERAL_CHAT | 결과 | 기여 |
|--------|----------|--------------|------|------|
| 1차 | Baseline 측정 | 61.5% | 문제 확인 | 문제 정의 |
| 2차 | POLICY_KEYWORDS 확장 | 61.5% | 변화 없음 | 서버 재시작 필요 발견 |
| 3차 | 서버 재시작 | 60.8% | 미미한 변화 | pycache 문제 발견 |
| 4차 | pycache 삭제 | 60.8% | 미미한 변화 | **IntentService 외 문제 확인** |
| 5차 | "하" 키워드 제거 | **0.0%** | **극적 개선** | 근본 원인 해결 |

### 5.6 디버깅 과정의 교훈

| 교훈 | 상세 |
|------|------|
| **환경 일관성** | 코드 변경 시 pycache 삭제 + 서버 재시작 필수 |
| **단위 테스트 활용** | 컴포넌트별 격리 테스트로 문제 범위 좁히기 |
| **가설 검증 반복** | 한 번의 실패로 포기하지 않고 다른 가설로 전환 |
| **파이프라인 추적** | 입력 → 출력 전체 흐름을 단계별로 검증 |

---

## 6. 개선 작업

### 6.1 수정 내역

#### 수정 1: COMPLAINT_KEYWORDS에서 "하" 제거
**파일**: `app/services/answer_guard_service.py`

```python
# Before (문제 코드)
COMPLAINT_KEYWORDS: Set[str] = {
    "그지", "왜몰라", "뭐하", "답답", "짜증", "개같", "멍청", "병신", "꺼져",
    "미친", "지랄", "시발", "씨발", "ㅅㅂ", "ㅂㅅ", "아씨", "에휴", "아오",
    "대체왜", "못알아", "모르냐", "이게뭐야", "쓸모없", "뭐냐", "하",  # ← 문제
}

# After (수정 코드)
COMPLAINT_KEYWORDS: Set[str] = {
    "그지", "왜몰라", "뭐하", "답답", "짜증", "개같", "멍청", "병신", "꺼져",
    "미친", "지랄", "시발", "씨발", "ㅅㅂ", "ㅂㅅ", "아씨", "에휴", "아오",
    "대체왜", "못알아", "모르냐", "이게뭐야", "쓸모없", "뭐냐",
    # Phase 43: "하" 제거 - 한국어 동사 기본형이므로 너무 광범위함
}
```

#### 수정 2: POLICY_KEYWORDS 확장 (선행 작업)
**파일**: `app/services/intent_service.py`

Q세트 도메인에 맞춰 정책 키워드 126개로 확장:
- 사규/복무: 근무시간, 휴게시간, 지각, 결근, 재택근무, 연장근로, 인사평가 등
- 개인정보보호: 개인정보, 민감정보, USB, 암호화, CCTV 등
- 성희롱 방지: 성희롱, 성적수치심, 피해자보호, 2차피해 등
- 직장내괴롭힘: 괴롭힘, 폭언, 따돌림, 업무배제, 갑질 등
- 장애인식: 장애인, 합리적편의, 차별금지, 편의제공 등
- 직무교육: 소스코드, 오픈소스, 라이선스, AI, 보안점검 등

### 6.2 파이프라인 흐름 개선

```
[Before - 문제 흐름]
User Query → Complaint Check("하" 매칭) → 즉시 템플릿 반환
                    ↓
              Intent/RAG/LLM 스킵

[After - 정상 흐름]
User Query → Complaint Check(패스) → Intent 분류 → RAG 검색 → LLM 생성 → 응답
                                          ↓
                                   POLICY_QA로 분류
```

---

## 7. 5차 테스트 결과 (개선 후)

### 7.1 테스트 일시
2025-12-23 20:45 ~ 20:56

### 7.2 결과 요약

#### 인텐트 분류 결과
| 인텐트 | 건수 | 비율 |
|--------|------|------|
| POLICY_QA | 64 | 49.2% |
| EDUCATION_QA | 38 | 29.2% |
| INCIDENT_QA | 17 | 13.1% |
| EDU_STATUS | 6 | 4.6% |
| INCIDENT_REPORT | 3 | 2.3% |
| SYSTEM_HELP | 2 | 1.5% |
| **GENERAL_CHAT** | **0** | **0.0%** |

#### 라우팅 결과
| 라우트 | 건수 | 비율 |
|--------|------|------|
| RAG_INTERNAL | 119 | 91.5% |
| BACKEND_API | 8 | 6.2% |
| LLM_ONLY | 2 | 1.5% |
| MIXED_BACKEND_RAG | 1 | 0.8% |

---

## 8. 성능 개선 비교

### 8.1 정량적 비교

| 지표 | 1차 (Before) | 5차 (After) | 개선폭 |
|------|-------------|-------------|--------|
| GENERAL_CHAT | 61.5% (80건) | **0.0%** (0건) | **-61.5%p** |
| LLM_ONLY | 63.1% (82건) | **1.5%** (2건) | **-61.6%p** |
| RAG_INTERNAL | 36.2% (47건) | **91.5%** (119건) | **+55.3%p** |
| 소스 포함 | 28.5% (37건) | **63.1%** (82건) | **+34.6%p** |
| 템플릿 폴백 | 79건 | **0건** | **-79건** |
| 평균 응답시간 | 1,484ms | 4,271ms | +2,787ms |

### 8.2 개선율 시각화

```
GENERAL_CHAT 오분류율
1차: ████████████████████████████████████████████████████████████░ 61.5%
5차: ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░   0.0%

RAG 검색 수행율
1차: ████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 36.2%
5차: ████████████████████████████████████████████████████████████░ 91.5%

소스 포함 답변율
1차: ███████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 28.5%
5차: ████████████████████████████████████████████░░░░░░░░░░░░░░░░ 63.1%
```

### 8.3 응답 시간 분석

| 구분 | 설명 |
|------|------|
| 1차 (1,484ms) | Complaint Fast Path로 인해 비정상적으로 빠름 (79건이 ~10ms 내 반환) |
| 5차 (4,271ms) | RAG 검색 + LLM 생성의 정상적인 처리 시간 |
| 해석 | 응답 시간 증가는 **정상적인 파이프라인 동작**의 증거 |

---

## 9. 기술적 인사이트

### 9.1 한국어 NLP 특수성

| 문제 | 원인 | 교훈 |
|------|------|------|
| "하" 오탐지 | 한국어 동사 활용의 기본형 | 단일 음절 키워드는 위험 |
| 광범위 매칭 | "~하나요?", "~해야", "~하고" 등 | 어미/조사 결합 고려 필요 |

**권장 사항**:
- 단일 음절 키워드 사용 지양
- 정규표현식 기반 패턴 매칭 도입 (`하\s*$` 등)
- 형태소 분석기 활용 검토

### 9.2 파이프라인 설계 원칙

```
[Anti-Pattern] 전처리에서 광범위 필터링
Input → 광범위 필터 → (대부분 차단) → 정상 처리

[Best Practice] 전처리는 최소화, 후처리에서 검증
Input → 최소 필터 → 정상 처리 → 후처리 검증 → Output
```

### 9.3 테스트 주도 디버깅

| 단계 | 활용 기법 |
|------|----------|
| 1 | 응답 시간 패턴 분석 (< 20ms vs > 1s) |
| 2 | 응답 템플릿 역추적 |
| 3 | 키워드 매칭 검증 스크립트 |
| 4 | 단위 테스트로 분류 로직 검증 |

---

## 10. 결론

### 10.1 성과 요약

1. **의도 분류 정확도 대폭 개선**: GENERAL_CHAT 오분류 61.5% → 0%
2. **RAG 활용률 향상**: 36.2% → 91.5%
3. **근거 기반 답변 증가**: 소스 포함율 28.5% → 63.1%
4. **템플릿 폴백 제거**: 79건 → 0건

### 10.2 핵심 개선 요인

| 순위 | 개선 항목 | 기여도 |
|------|----------|--------|
| 1 | COMPLAINT_KEYWORDS "하" 제거 | **결정적** (79건 복구) |
| 2 | POLICY_KEYWORDS 확장 | 보조적 (정확도 향상) |

### 10.3 향후 개선 방향

1. **형태소 분석기 도입**: 키워드 매칭의 정밀도 향상
2. **ML 기반 Intent Classifier**: 규칙 기반 한계 극복
3. **RAG 검색 품질 개선**: 소스 포함율 63% → 80% 이상 목표
4. **A/B 테스트 체계 구축**: 지속적 성능 모니터링

---

## 부록

### A. 테스트 스크립트
- 파일: `scripts/test_qset.py`
- 기능: CSV 기반 배치 테스트 및 결과 분석

### B. 수정 파일 목록
| 파일 | 수정 내용 |
|------|----------|
| `app/services/answer_guard_service.py` | COMPLAINT_KEYWORDS에서 "하" 제거 |
| `app/services/intent_service.py` | POLICY_KEYWORDS 126개로 확장 |

### C. 테스트 데이터
- 입력: `data/Q세트.csv` (130문항)
- 출력: `data/Q세트_테스트결과.csv`

---

**작성일**: 2025-12-23
**작성자**: CTRL+F AI 개발팀
