# **AI 품질개선 로깅 & 관리자 대시보드 지표 계약서**

## **0) 한 줄 요약**

- *AI는 “구조화 이벤트(로그) 발행자”, 백은 “집계/권한/캐시/API 제공자”, 프론트는 “대시보드 렌더러”**로 역할을 분리한다.

대시보드(챗봇/지표 탭)에서 보이는 모든 수치는 **(AI 이벤트 → 백 집계 → 프론트 조회)**로 만든다.

---

## **1) 목표와 원칙**

### **목표(MVP)**

- 모든 대화 턴에 대해 **구조화 이벤트** 수집(질문/답변/의도/라우팅/성능/피드백/에러/PII).
- 관리자 대시보드에서 **기간/부서 필터 기반 KPI** 제공(오늘/최근 7일/30일/90일).
- 👎/에러/재질문/이관 기반 **bad_case 큐** 생성 → (선택) self-eval로 실패 유형 태깅.
- (고도화) 질문 로그 기반 **FAQ 후보 자동 선정 + AI 초안 생성 + 관리자 승인 후 등록**.

### **절대 원칙(구멍 방지)**

- **채팅 응답 경로와 로그 저장 경로 분리**(로그 장애가 응답 장애로 번지면 안 됨).
- **PII는 저장 전 마스킹/비식별**(원문 저장 금지 원칙).
- **trace_id로 상관관계 보장**(프론트/백/AI 요청을 한 줄로 추적).
- 대시보드 지표는 **AI가 직접 계산해서 프론트로 주지 않고**, 반드시 **백이 집계해서 제공**(권한/필터/캐시 때문).

---

## **2) 전체 흐름(Feedback Loop)**

```mermaid
flowchart TD
  U[User question] --> A[AI answer generation]
  A --> EV[Emit structured events]
  EV --> BE[Backend ingest + store]
  BE --> AGG[Aggregate KPIs + build queues]
  AGG --> ADM[Admin dashboard APIs]
  ADM --> FE[Frontend dashboard]
  AGG --> BC[bad_case queue]
  BC --> SE[Self-eval worker batch]
  SE --> IC[Improvement candidates]
  IC --> AP[Admin approval]
  AP --> AGG

```

---

## **3) 시스템 역할 분담 (AI ↔ 백 ↔ 프론트)**

### **AI(필수)**

- 각 턴마다 **구조화 이벤트 발행**
    - route_type(RAG/API/GENERAL), domain, latency, error_code
    - PII 탐지/차단 여부
    - (RAG면) 사용된 문서/스코어 요약
- 이벤트에는 반드시 **`trace_id`**, **`conversation_id`**, **`turn_id`** 포함

### **백(필수)**

- 이벤트 **수집/저장/집계/권한/캐시** 담당
- 대시보드 API 제공(기간/부서 필터 반영)
- self-eval/FAQ 후보 등 배치 작업(필요 시 워커 분리)

### **프론트**

- 대시보드 UI 렌더링
- 기간/부서 필터, 새로고침 버튼은 **백 API 재호출**로 동작

---

## **4) 이벤트 스키마(최소) — “AI가 백으로 보내는 원천”**

> 이벤트 타입은 3개만으로도 MVP 가능
> 

### **4.1 ChatTurnEvent (턴 단위 핵심 이벤트)**

| **필드** | **설명** |
| --- | --- |
| trace_id | 요청 상관관계 키 |
| conversation_id | 세션 ID |
| turn_id | 턴 번호 |
| user_id | 내부 사용자 ID(텍스트 PII 금지) |
| dept_id | 부서 ID(권장: 백이 AI 호출 시 전달) |
| timestamp | 발생 시각 |
| user_query_masked | 마스킹된 질문 |
| assistant_answer_masked | 마스킹된 답변 |
| intent_main / intent_sub | 의도 |
| route_type | RAG / EDU_API / QUIZ_API / REPORT_API / GENERAL / OOS |
| domain | POLICY / FAQ / EDUCATION / QUIZ / ETC |
| model | 사용 모델명(예: gpt-4o-mini 등) |
| latency_ms_total | 총 응답시간 |
| latency_ms_llm | LLM 시간(가능하면) |
| latency_ms_retrieval | 검색/재랭크 시간(가능하면) |
| rag_used | true/false |
| error_code | 없으면 null |
| pii_detected_input | true/false |
| pii_detected_output | true/false |

### **4.2 FeedbackEvent (사용자 평가)**

| **필드** | **설명** |
| --- | --- |
| trace_id / conversation_id / turn_id | 어떤 턴 평가인지 |
| user_id / dept_id | 집계용 |
| feedback | like / dislike |
| created_at | 평가 시각 |

### **4.3 SecurityEvent (차단/보안 이벤트)**

| **필드** | **설명** |
| --- | --- |
| trace_id (선택) | 특정 턴과 연결되면 포함 |
| user_id / dept_id | 집계용 |
| block_type | PII_BLOCK / EXTERNAL_DOMAIN_BLOCK |
| blocked | true |
| created_at | 발생 시각 |

---

## **5) 저장/분석 스택 역할(현실 스코프)**

- **ELK(선택)**: 운영 로그 탐색/시계열 집계/대시보드에 강점
- **Milvus(선택, 고도화)**: “유사 질문/클러스터링/FAQ 후보 군집”에만 사용
    - 로그 저장소가 아니라 **유사도 분석 엔진**으로 붙이는 게 정석

---

## **6) 관리자 대시보드 지표 계약(Metrics Contract)**

> 아래 표가 “프론트 위젯 ↔ 필요한 이벤트/필드 ↔ 계산식”의 계약서다.프론트에 구현된 위젯(챗봇 탭/지표 탭)은 전부 이 방식으로 백이 만들어서 내려준다.
> 

### **6.1 공통 필터/집계 규칙**

- 기간 필터: **`today / last_7d / last_30d / last_90d`**
- 부서 필터: **`dept_id`** 기준(“전체 부서”는 all)
- 분모 규칙(중요):
    - 만족도/불만족도는 **피드백이 달린 턴만** 분모로 사용(권장)
    - 비율 지표는 **`0으로 나눔`** 방지(평가 0이면 null 또는 0으로 표시 정책)

---

## **7) 프론트 위젯별 매핑 표 (챗봇 탭 + 지표 탭)**

### **7.1 챗봇 탭(요약 카드/차트/도메인 비율)**

| **위젯(프론트)** | **백 API 응답 필드 예시** | **소스 이벤트** | **계산식(요약)** | **MVP/고도화** |
| --- | --- | --- | --- | --- |
| 오늘 질문 수 | **`today_question_count`** | ChatTurnEvent | 기간=today, count(*) | MVP |
| 최근 7일 질문 수(및 일평균) | **`last7_count`**, **`last7_daily_avg`** | ChatTurnEvent | 7일 count, /7 | MVP |
| 활성 사용자 수(최근 30일) | **`active_users_30d`** | ChatTurnEvent | 30일 distinct(user_id) | MVP |
| 평균 응답 시간 | **`avg_latency_ms`** | ChatTurnEvent | avg(latency_ms_total) | MVP |
| PII 감지 비율 | **`pii_detect_rate`** | ChatTurnEvent | (pii_detected_input OR output) / total | MVP |
| 에러율 | **`error_rate`** | ChatTurnEvent | error_code not null / total | MVP |
| 응답 만족도(%) | **`satisfaction_rate`** | FeedbackEvent | like / (like+dislike) | MVP |
| RAG 사용 비율 | **`rag_usage_rate`** | ChatTurnEvent | rag_used=true / total | MVP |
| 질문 수·에러율 추이(주별) | **`weekly_series[]`** | ChatTurnEvent | week bucket: count, error_rate | MVP |
| 도메인별 질문 비율 | **`domain_share[]`** | ChatTurnEvent | group by domain ratio | MVP |

### **7.2 지표 탭(보안·PII / 성능·장애)**

| **위젯(프론트)** | **백 API 응답 필드 예시** | **소스 이벤트** | **계산식(요약)** | **MVP/고도화** |
| --- | --- | --- | --- | --- |
| PII 차단 횟수 | **`pii_block_count`** | SecurityEvent | block_type=PII_BLOCK count | MVP |
| 외부 도메인 차단 | **`external_domain_block_count`** | SecurityEvent | block_type=EXTERNAL_DOMAIN_BLOCK count | MVP |
| PII 감지 추이(입력/출력) | **`pii_trend[]`** | ChatTurnEvent | week bucket: input_detect_rate, output_detect_rate | MVP |
| 답변 불만족 비율 | **`dislike_rate`** | FeedbackEvent | dislike/(like+dislike) | MVP |
| 재질문 비율 | **`repeat_rate`** | ChatTurnEvent | 아래 “재질문 정의” 참고 | MVP(단순) / 고도화(유사도) |
| Out-of-scope 응답 수 | **`oos_count`** | ChatTurnEvent | route_type=OOS count | MVP |
| 응답 시간 분포 | **`latency_histogram[]`** | ChatTurnEvent | bucket: 0-500, 0.5-1s, 1-2s, 2s+ count | MVP |
| 모델별 평균 응답 시간 | **`model_latency[]`** | ChatTurnEvent | group by model avg(latency) | MVP |
| 재랭크 포함 평균(선택) | **`avg_latency_with_rerank`** | ChatTurnEvent | avg(latency_ms_total) 또는 단계 합산 | 고도화(필드 준비 시) |

---

## **8) 재질문 비율 정의(가장 먼저 “스코프 컷” 해야 하는 부분)**

### **MVP(단순/확실) 정의(권장)**

- 같은 **`conversation_id`** 안에서 **N턴 이내** 동일 **`intent_main`**이 반복되면 재질문으로 카운트
    - 예: N=3, “같은 주제 2회 이상 재질문한 세션 비율”

### **고도화(정확도 ↑, 비용 ↑)**

- (선택) 질문 임베딩 기반 유사도(예: Milvus TopK)로 “유사 질문 반복” 판정

---

## **9) 대시보드 API 설계(백 → 프론트)**

> 프론트는 아래 API만 호출. 백은 권한/캐시/필터 적용.
> 

### **9.1 챗봇 탭 요약/차트**

- **`GET /admin/dashboard/chat/summary?period=30d&dept=all`**
- **`GET /admin/dashboard/chat/trends?period=30d&dept=all&bucket=week`**
- **`GET /admin/dashboard/chat/domain-share?period=30d&dept=all`**

### **9.2 지표 탭(보안/성능)**

- **`GET /admin/dashboard/metrics/security?period=30d&dept=all`**
- **`GET /admin/dashboard/metrics/performance?period=30d&dept=all`**

### **9.3 캐시/새로고침 정책(권장)**

- 기본: 1~5분 캐시(대시보드 “새로고침” 버튼은 캐시 무시 옵션으로 재호출)
- 배치 집계(선택): 5~15분 단위로 집계 테이블/인덱스 갱신

---

## **10) bad_case / self-eval / 개선 후보 / FAQ 후보(품질 순환)**

### **10.1 bad_case 트리거(MVP 권장 순서)**

1. dislike(👎)
2. error(error_code 존재)
3. out-of-scope
4. repeat(재질문, 정의 확정 후)

### **10.2 self-eval(선택, MVP-2)**

- **bad_case만** 배치로 평가해서 **`issue_type`**, **`suggested_fix`** 저장

### **10.3 FAQ 후보 자동 생성(고도화)**

- 비식별 질문 로그 분석 → 유사 질문 군집 → 후보 점수(빈도 + 👍 가중치 ↑ / 👎 가중치 ↓)
- AI가 FAQ 초안(Q/A) 생성
- **관리자 승인 후 등록**(자동 반영 금지)

---

## **11) 보안/운영 정책(필수)**

- PII: 저장 전 마스킹(원문 저장 금지)
- 보존기간: 상세 텍스트는 기간 후 삭제, 집계는 유지
- 접근제어: 관리자/권한 롤만 조회
- 변경이력: 승인/적용은 audit으로 남김
- 장애정책: 로그 파이프라인 장애 시 **채팅 우선**, 로그는 드랍/샘플링 허용

---

## **12) MVP 컷라인(중요도 낮은 파이프라인 쳐내기)**

### **MVP-1(필수)**

- ChatTurnEvent + FeedbackEvent + SecurityEvent 수집
- 챗봇 탭/지표 탭 KPI(기간/부서 필터) 제공
- 재질문은 단순 정의로 시작

### **MVP-2(선택)**

- bad_case 자동 큐 + self-eval 배치 태깅

### **MVP-3(고도화)**

- Milvus로 유사질문 군집 → FAQ 후보 자동 생성 → 관리자 승인 등록
- 변경 전/후 품질 비교 리포트 강화








# **API 명세서 v1 — 로깅/대시보드 계약 (AI ↔ 백 ↔ 프론트)**

## **0) 범위(MVP 확정)**

- **AI → 백**: 원천 이벤트(로그) 수집 API **1개로 통일**
- **프론트 → 백**: 관리자 대시보드 조회 API **탭 기준 5개**
- **백 → AI**: **`trace_id/user_id/dept_id`** **전파 규칙 확정(헤더)**
- Self-eval/FAQ 후보 생성은 **v1에 “예약(확장)”만 해두고, MVP 구현 범위 제외**

---

## **1) 공통 규칙**

### **1.1 인증/헤더**

- 내부 호출 인증: **`X-Internal-Token: <token>`**
- 콘텐츠 타입: **`Content-Type: application/json`**
- 상관관계(필수): **`X-Trace-Id: <uuid>`**
    
    (백이 생성해서 프론트↔백↔AI 전 구간에 전파)
    

### **1.2 시간/포맷**

- **`timestamp/occurredAt`**: ISO-8601 (예: **`2025-12-30T21:10:22+09:00`**)
- **`period`** enum: **`today | 7d | 30d | 90d`**
- **`bucket`** enum: **`day | week`**
- **`dept`** 값: **`all`** 또는 **`dept_id`** 문자열

### **1.3 에러 응답 표준**

```json
{
"errorCode":"STRING_ENUM",
"message":"human readable",
"traceId":"uuid"
}

```

---

## **2) Trace / 조직 정보 전파 규칙 (백 → AI 요청 계약)**

백이 AI 호출할 때 **반드시 헤더로 전달**:

- **`X-Trace-Id`** (필수)
- **`X-User-Id`** (필수)
- **`X-Dept-Id`** (필수, 부서 필터 사용을 위해 권장 필수로 고정)
- **`X-Conversation-Id`** (권장)
- **`X-Turn-Id`** (권장)

> AI는 이 값을 그대로 이벤트에 포함해서 백으로 전송한다.
> 

---

## **3) AI → 백 : Telemetry(로그 이벤트) 수집 API (확정)**

### **3.1 POST `/internal/telemetry/events`**

**설명**: AI가 생성한 구조화 이벤트를 백으로 전송한다.

**특징**: 배치 전송 지원, **idempotent**(중복 eventId는 무시/동일처리).

### **Request Body**

```json
{
"source":"ai-gateway",
"sentAt":"2025-12-30T21:10:22+09:00",
"events":[
{
"eventId":"b9b2f9f9-1f7a-4ad4-9db5-4a1cf2d6b3d1",
"eventType":"CHAT_TURN",
"traceId":"9de2d2d0-3c9c-4c60-bda6-1c0e1c2a4c55",
"conversationId":"C-20251230-000123",
"turnId":7,
"userId":"U-10293",
"deptId":"D-SALES",
"occurredAt":"2025-12-30T21:10:21+09:00",
"payload":{}
}
]
}

```

### **Response 200**

```json
{
"received":10,
"accepted":9,
"rejected":1,
"errors":[
{"eventId":"....","errorCode":"INVALID_FIELD","message":"turnId is required"}
]
}

```

### **Response Codes**

- 200: 수신 완료(부분 실패 포함)
- 401/403: 토큰 오류
- 413: payload 너무 큼
- 429: 수집기 과부하(백이 레이트 제한)
- 500: 서버 오류

---

## **4) 이벤트 타입 스키마 (확정)**

### **4.1 `eventType = CHAT_TURN`**

**목적**: 대시보드 대부분 KPI의 원천

```json
{
"intentMain":"POLICY_QA",
"intentSub":"PARENTAL_LEAVE",
"routeType":"RAG",
"domain":"POLICY",
"model":"gpt-4o-mini",
"ragUsed":true,

"latencyMsTotal":415,
"latencyMsLlm":280,
"latencyMsRetrieval":90,

"errorCode":null,

"piiDetectedInput":false,
"piiDetectedOutput":false,

"oos":false,

"rag":{
"retriever":"milvus",
"topK":5,
"minScore":0.58,
"maxScore":0.63,
"avgScore":0.60,
"sources":[
{"docId":"POL-001","chunkId":12,"score":0.63}
],
"contextExcerpt":"optional-short-excerpt-max-300-chars"
}
}

```

**제약**

- **`contextExcerpt`**는 **선택**이고 길이 제한(예: 300자) 필수
- **`errorCode`**는 없으면 **`null`**
- **`oos=true`**면 **`routeType`**은 **`OOS`** 권장

---

### **4.2 `eventType = FEEDBACK`**

**목적**: 만족도/불만족도 지표

```json
{
"feedback":"like",
"targetConversationId":"C-20251230-000123",
"targetTurnId":7
}

```

**제약**

- FEEDBACK는 반드시 특정 턴을 가리켜야 함(**`targetConversationId`**, **`targetTurnId`**)

---

### **4.3 `eventType = SECURITY`**

**목적**: PII 차단/외부 도메인 차단 등 보안 지표

```json
{
"blockType":"PII_BLOCK",
"blocked":true,
"ruleId":"PII-RULE-001"
}

```

**`blockType`** enum:

- **`PII_BLOCK`**
- **`EXTERNAL_DOMAIN_BLOCK`**

---

## **5) 백 → 프론트 : 관리자 대시보드 API (확정)**

> 공통: period, dept는 모든 API에 포함공통: refresh=true면 캐시 무시(“데이터 새로고침” 버튼과 연결)
> 

### **5.1 GET `/admin/dashboard/chat/summary?period=30d&dept=all&refresh=false`**

**설명**: 챗봇 탭 상단 요약 카드

### **Response 200**

```json
{
"period":"30d",
"dept":"all",

"todayQuestionCount":158,
"periodQuestionCount":3516,
"periodDailyAvgQuestionCount":879,

"activeUsers":102,

"avgLatencyMs":415,

"piiDetectRate":0.034,
"errorRate":0.009,

"satisfactionRate":0.92,
"dislikeRate":0.042,

"ragUsageRate":0.80
}

```

**정의(중요)**

- **`satisfactionRate = like / (like + dislike)`**
- **`dislikeRate = dislike / (like + dislike)`**
- (권장) 분모가 0이면 **`null`** 반환

---

### **5.2 GET `/admin/dashboard/chat/trends?period=30d&dept=all&bucket=week`**

**설명**: 질문 수·에러율 추이(주/일)

### **Response 200**

```json
{
"bucket":"week",
"series":[
{"bucketStart":"2025-12-02","questionCount":780,"errorRate":0.009},
{"bucketStart":"2025-12-09","questionCount":842,"errorRate":0.009}
]
}

```

---

### **5.3 GET `/admin/dashboard/chat/domain-share?period=30d&dept=all`**

**설명**: 도메인별 질문 비율(규정/FAQ/교육/퀴즈/기타)

### **Response 200**

```json
{
"items":[
{"domain":"POLICY","label":"규정 안내","questionCount":1266,"share":0.36},
{"domain":"FAQ","label":"FAQ","questionCount":914,"share":0.26},
{"domain":"EDUCATION","label":"교육","questionCount":668,"share":0.19},
{"domain":"QUIZ","label":"퀴즈","questionCount":387,"share":0.11},
{"domain":"ETC","label":"기타","questionCount":281,"share":0.08}
]
}

```

---

### **5.4 GET `/admin/dashboard/metrics/security?period=30d&dept=all`**

**설명**: 지표 탭 — 보안·PII

### **Response 200**

```json
{
"piiBlockCount":128,
"externalDomainBlockCount":36,

"piiTrend":[
{"bucketStart":"2025-12-02","inputDetectRate":0.044,"outputDetectRate":0.030},
{"bucketStart":"2025-12-09","inputDetectRate":0.041,"outputDetectRate":0.028}
]
}

```

---

### **5.5 GET `/admin/dashboard/metrics/performance?period=30d&dept=all`**

**설명**: 지표 탭 — 성능·장애

### **Response 200**

```json
{
"dislikeRate":0.042,

"repeatRate":0.17,
"repeatDefinition":"MVP: same conversation, within last 3 turns, same intentMain repeated",

"oosCount":23,

"latencyHistogram":[
{"range":"0-500ms","count":1280},
{"range":"0.5-1s","count":530},
{"range":"1-2s","count":260},
{"range":"2s+","count":71}
],

"modelLatency":[
{"model":"gpt-4o-mini","avgLatencyMs":430},
{"model":"gpt-4.1","avgLatencyMs":760}
]
}

```

---

## **6) (예약) Self-eval / FAQ 후보 관련 API — v1 “스펙만 예약”, MVP 제외**

> 엔드포인트/스키마는 확장 시 추가 (지금은 구현 요청하지 않음)
> 
- **`/internal/quality/bad-cases`** (생성/조회)
- **`/internal/quality/evaluations`** (self-eval 결과 저장)
- **`/internal/quality/faq-candidates`** (FAQ 후보 생성/승인 플로우)

---

## **7) 구현 요청 시 “백/프론트에 전달할 최소 티켓”**

### **백엔드(필수)**

1. Telemetry 수집 API: **`POST /internal/telemetry/events`**
2. 대시보드 조회 API 5개 구현
3. **`period/dept`** 필터 + 캐시(**`refresh=true`** 캐시 무시)
4. 지표 계산식(만족도 분모 규칙 포함) 고정
5. 권한: SYSTEM_ADMIN만 접근

### **프론트(필수)**

1. 기존 위젯 유지 + 백 API 연결
2. 필터(period/dept) 쿼리만 맞춰 전송
3. “데이터 새로고침” = **`refresh=true`**로 재호출

**각 요소가 필요한 이유**

## **1) 공통 헤더/규칙 — 필요한 이유 한 마디**

- **X-Internal-Token**: 내부 API를 외부에서 못 치게 막는 최소 보안장치.
- **Content-Type: application/json**: 이벤트/대시보드 모두 구조화 데이터라 파싱/검증 표준화가 필요.
- **X-Trace-Id**: 한 사용자 요청이 프론트→백→AI→백 집계까지 “한 줄로” 추적되게 해줌(장애/지연 원인 찾기).
- **기간(period)**: 대시보드는 “오늘/최근 7일/30일” 같은 기준 없으면 지표 해석이 불가능.
- **버킷(bucket day/week)**: 추이를 그리려면 집계 단위(일/주)가 고정돼야 프론트가 안정적으로 그릴 수 있음.
- **dept(부서 필터)**: 관리자 대시보드는 “조직별 품질/사용량”이 핵심이라 부서 차원 집계가 필요.
- **표준 에러 응답(traceId 포함)**: 프론트/운영자가 에러 한 번 봤을 때 바로 서버 로그/트레이스를 따라갈 수 있음.

---

## **2) 백 → AI 전파 헤더 — 필요한 이유 한 마디**

- **X-User-Id**: 사용자/권한/활성 사용자 수 같은 기본 KPI의 분모를 만들기 위해 필요.
- **X-Dept-Id**: 부서 집계는 AI가 스스로 알 수 없어서 백이 전달해야 함(나중에 조인하면 복잡해짐).
- **X-Conversation-Id**: 세션 단위 지표(재질문, 이관 흐름, 대화 길이)를 계산하려면 필요.
- **X-Turn-Id**: 특정 답변(턴)에 대한 피드백/이슈를 정확히 매칭하려면 필요.

---

## **3) AI → 백 Telemetry 수집 API — 필요한 이유 한 마디**

- **POST /internal/telemetry/events “1개로 통일”**: 이벤트 수집 경로가 여러 개면 운영/보안/스키마가 바로 깨져서 단일화가 필요.
- **배치 전송(events[])**: 스파이크 때 네트워크 호출을 줄여 응답 성능과 비용을 안정화.
- **eventId**: 재전송/중복 전송이 와도 “중복 집계”를 막기 위한 안전장치.
- **source / sentAt**: 어떤 서비스가 언제 보냈는지 추적해야 장애/유실 분석이 가능.
- **accepted/rejected + errors[]**: 이벤트 일부가 깨져도 전체가 죽지 않게 하고, 어떤 이벤트가 왜 실패했는지 즉시 알기 위해 필요.

---

## **4) 이벤트 타입별 payload 필드 — 필요한 이유 한 마디**

### **4.1 CHAT_TURN (대시보드의 원천)**

- **intentMain/intentSub**: “어느 의도에서 품질이 떨어지는지”를 정량화하려면 필요.
- **routeType**: RAG로 갔는지 API로 갔는지 알아야 “라우팅 실패”를 측정하고 개선할 수 있음.
- **domain**: 프론트의 도메인 비율/도메인별 KPI 차트를 만들기 위한 분류 키.
- **model**: 모델 변경/혼용 시 “성능·만족도 차이”를 비교하려면 필요.
- **ragUsed**: RAG 사용률/비사용률(=OOS/일반답변 포함) 같은 핵심 지표 계산에 필요.
- **latencyMsTotal**: 사용자 체감 품질의 핵심(느리면 불만족이 늘어남)이라 필수.
- **latencyMsLlm / latencyMsRetrieval**: 느린 원인이 LLM인지 검색인지 분해해야 최적화 방향이 나옴.
- **errorCode**: 에러율/장애 트래킹 및 “실패 케이스 자동 수집”의 트리거가 됨.
- **piiDetectedInput / piiDetectedOutput**: PII 위험도를 정량화하고 차단 정책을 튜닝하려면 필요.
- **oos**: “대답을 못하는 케이스”를 따로 집계해야 지식/규칙 보강 우선순위를 잡을 수 있음.

### **RAG 서브필드**

- **retriever**: 검색 백엔드별(밀버스/기타) 품질 비교/장애 분석에 필요.
- **topK**: 검색 정책 변경이 품질에 미치는 영향을 추적하려면 필요.
- **min/max/avgScore**: “검색이 약한지(유사도 낮음)”를 수치로 감지하는 근거가 됨.
- **sources(docId/chunkId/score)**: “어떤 문서/청크 때문에 답변이 이랬는지” 근거 추적용.
- **contextExcerpt(짧게)**: 디버깅/운영 확인용 최소 힌트(단, 길이 제한으로 PII/보안 리스크 최소화).

### **4.2 FEEDBACK**

- **feedback(like/dislike)**: 만족도 KPI의 직접 데이터라 필수.
- **targetConversationId/targetTurnId**: 피드백이 “어떤 답변”에 달렸는지 정확히 연결해야 개선이 가능.

### **4.3 SECURITY**

- **blockType**: PII 차단인지 외부 도메인 차단인지 구분해야 보안 지표가 의미가 생김.
- **blocked=true**: 실제로 차단이 발생했는지(탐지만 했는지) 구분이 필요.
- **ruleId**: 어떤 규칙 때문에 차단됐는지 알아야 정책 튜닝/오탐 개선이 가능.

---

## **5) 백 → 프론트 대시보드 API(5개) — 필요한 이유 한 마디**

### **5.1 /chat/summary**

- **요약 카드**는 “서비스가 잘 쓰이고 있는지/품질이 어떤지”를 한 번에 보여주는 최소 대시보드 핵심이라 필요.

### **5.2 /chat/trends**

- **추이**가 없으면 개선 전/후를 비교할 수 없어서 “품질 개선 효과”를 증명할 수 없음.

### **5.3 /chat/domain-share**

- 도메인 비율이 있어야 “어느 영역이 가장 많이 쓰이고 이슈가 많은지” 우선순위를 잡을 수 있음.

### **5.4 /metrics/security**

- 보안(PII/차단)은 운영 리스크라 “수치로 모니터링”하지 않으면 사고 대응이 늦어짐.

### **5.5 /metrics/performance**

- 성능/장애/불만족/재질문은 사용자 체감 품질의 핵심이라 별도 탭으로 집중 관리가 필요.

### **공통 파라미터**

- **period/dept**: 같은 화면이라도 기간/부서에 따라 해석이 달라서 필터는 필수.
- **refresh**: 캐시가 있을 때 운영자가 “지금 상황”을 확인하려면 강제 갱신이 필요.

---

## **6) 계산식/정의 — 필요한 이유 한 마디**

- **satisfactionRate = like/(like+dislike)**: “평가가 있는 표본”만으로 만족도를 정의해야 지표가 왜곡되지 않음.
- **분모가 0이면 null**: 0으로 나눔을 막고, “표본이 부족”하다는 의미를 UI에서 표현 가능.
- **repeatRate MVP 정의(동일 intent 반복)**: 처음부터 유사도까지 하면 비용/복잡도가 커서 MVP는 단순 정의로 빠르게 측정이 필요.
- **latency histogram**: 평균만 보면 “꼬리 지연(p95)”을 놓치기 때문에 분포가 필요.